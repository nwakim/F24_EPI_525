{
  "hash": "155011467907ed051a606dd366d8e9be",
  "result": {
    "markdown": "---\ntitle: \"Lesson 14: Power and sample size calculations for difference of means\"\nsubtitle: \"TB sections 5.4\"\nauthor: \"Meike Niederhausen and Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#3070BF\"\ndate: \"11/13/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: Lesson 14 Slides\n    html-math-method: mathjax\n    highlight-style: arrow\nexecute:\n  echo: true\n  freeze: auto\n---\n\n\n\n\n\n# Learning Objectives\n\n1. Understand the 4 components in equilibrium in a hypothesis test\n2. Define the significance level, critical value, and rejection region.\n3. Define power.\n4. Calculate power \n5. Calculate the sample size\n## Where are we?\n\n![](../img_slides/course_map.png){fig-align=\"center\"}\n\n## From Lesson 13: Does caffeine increase finger taps/min (on average)?\n\n-   [**Use this example to illustrate how to calculate a confidence interval and perform a hypothesis test for two independent samples**]{style=\"color:#5BAFF8\"}\n\n**Study Design**:[^1]\n\n[^1]: Based on following article with extra simulations by me: Hand, David J.; Daly, Fergus; McConway, K.; Lunn, D. and Ostrowski, E. (1993). [A handbook of small data sets](https://www.crcpress.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780412399206). London, U.K.: Chapman and Hall.\n\n-   70 college students students were trained to tap their fingers at a rapid rate\n-   Each then drank 2 cups of coffee (double-blind)\n    -   **Control** group: decaf\n    -   **Caffeine** group: \\~ 200 mg caffeine\n-   After 2 hours, students were tested.\n-   **Taps/minute** recorded\n\n\n\n\n\n## We started looking at the taps/min for each group\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Code to make these histograms\"}\nggplot(CaffTaps, aes(x=Taps)) +\n  geom_histogram() +\n  facet_wrap(vars(Group), ncol=1) +\n  labs(y = \"Number of people\", x = \"Taps/minute\") +\n  theme(text = element_text(size = 30))\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n## What if the following were the true population distributions? Case 1\n\n- Difference in population means is **5**\n- Both have a standard deviation of 2\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?\n  - **Depends on the number of samples we get: we might need a lot**\n\n## What if the following were the true population distributions? Case 2\n\n- Difference in population means is **5**\n- Both have a standard deviation of 1\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?\n  - **Seems easier to distinguish here.** How did the standard deviation decrease?\n\n## What if the following were the true population distributions? Case 3\n\n- Difference in population means is **10**\n- Both have a standard deviation of 2\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?\n  - **Also seems easier to distinguish here**\n\n  \n## There are a few things at play here\n\n- There are several measurements that affect how easy it is to distinguish between two populations \n- \"Distinguish between two populations\" = reject the null hypothesis that they are the same\n\n \n\n- What do we need?\n\n    1. **Difference** in population means\n    2. **Number of samples** from each population\n    3. The **significance level** that we use for a cut off\n    4. The **power** of our test\n    \n- More familiar with first two, but let's define #3 and #4 more\n\n# Learning Objectives\n\n## Significance levels and critical values \n\n::: {style=\"font-size: 90%;\"}\n\n* __Critical values__ are the cutoff values that determine whether a test statistic is statistically significant or not\n    - Determined by the **significance level**\n* If a test statistic is greater in absolute value than the critical value, we reject $H_0$\n\n \n\n::: columns\n::: {.column width=\"49%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\n\n* Critical values are determined by \n    * the significance level $\\alpha$, \n    * whether a test is 1- or 2-sided, &\n    * the probability distribution being used to calculate the p-value (such as normal or t-distribution)\n\n:::\n:::\n\n* We have been referring to critical values from the t-distribution as $t^*$\n    - See how we calculate a specific confidence interval\n:::\n\n## Poll Everywhere Question 1\n\n\n## Significance levels and critical values and rejection region\n\n* If the absolute value of the test statistic is greater than the critical value, we reject $H_0$\n    * In this case the test statistic is in the __rejection region__.\n    * Otherwise it's in the nonrejection region.\n\n::: columns\n::: {.column width=\"60%\"}\n\n![[Stats & Geospatial Analysis](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html)](../img_slides/RejectionRegion.png){fig-align=\"center\"}\n\n:::\n::: {.column width=\"40%\"}\n\n* What do rejection regions look like for 1-sided tests?\n\n:::\n:::\n\n\n# LOB\n\n## Let's start with some important definitions in words\n\n- **Type I error** ($\\alpha$): Probability of rejecting the null hypothesis given that the null is true\n- **Type II error** ($\\beta$): Probability of failing to reject the null hypothesis given that the null hypothesis is false\n- **Power** (or sensitivity) ($1 - \\beta$): Probability of rejecting the null hypothesis given that the null is false (correct)\n- **Specificity** ($1-\\alpha$): Probability of failing to reject the null hypothesis given that the null is true (correct)\n\n \n\n![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align=\"center\"}\n\n\n\n## What does that look like with our two populations?\n\n::: columns\n::: {.column width=\"45%\"}\n\n![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align=\"center\"}\n\n\n* [$\\alpha$]{style=\"color:violet\"} = probability of making a [__Type I error__]{style=\"color:violet\"}\n    * This is the significance level (usually 0.05)\n    * Set before study starts\n* [$\\beta$]{style=\"color:#5DCA3B\"} = probability of making a [__Type II error__]{style=\"color:#5DCA3B\"}\n* Ideally we want\n    * small Type I & II errors and\n    * big power\n\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n::: {style=\"font-size: 90%;\"}\n\n::: lob\n**Power** (or sensitivity) ($1 - \\beta$): Probability of rejecting the null hypothesis given that the null is false (correct)\n:::\n\n- Power is the correct region that is usually **in line with our study design**: studies are often seeing if there is a distinction between two populations\n\n:::\n\n:::\n:::\n\n## Power\n\n::: columns\n::: column\n- **Power** (or sensitivity) ($1 - \\beta$): Probability of rejecting the null hypothesis given that the null is false (correct)\n\n \n\n* Power is also called the\n    * true positive rate,\n    * probability of detection, or \n    * the _sensitivity_ of a test\n\n \n\n- Typically, we aim for 80% or 90% power\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## If you want to keep revisiting these concepts!\n        \nFrom the applet at <https://rpsychologist.com/d3/NHST/>\n\n::: columns\n::: {.column width=\"50%\"}\n\n![](../img_slides/power_applet_screenshot_alpha05.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](../img_slides/power_applet_screenshot_alpha01.png){fig-align=\"center\"}\n:::\n:::\n\n- Cohen's d is just a stanardized value to represent the difference in means: $$d = \\dfrac{\\overline{x}_1 - \\overline{x}_2}{s}$$\n\n# LOB\n\n## Example calculating power\n\n* Suppose the mean of the null population is 0 ( $H_0: \\mu=0$ ) with standard error 1\n* Find the power of a 2-sided test if the actual $\\mu=3$, assuming the SE doesn't change.\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n* Power = $P$ (Reject $H_0$ when alternative pop is true)\n  - Correctly reject null\n* When $\\alpha$ = 0.05, we reject $H_0$ when the test statistic z is at least 1.96\n* We need to look at the rejection region under the null, then calculate the probability that we are in those regions given we are actually in the alternative population\n* Thus for $X\\sim N(3,1)$ we need to calculate $P(X \\le -1.96) + P(X \\ge 1.96)$\n:::\n:::\n\n## Example calculating power: using `pnorm()`\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n* Thus for $X\\sim N(3,1)$ we need to calculate $P(X \\le -1.96) + P(X \\ge 1.96)$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# left tail + right tail:\npnorm(-1.96, mean=3, sd=1, \n      lower.tail=TRUE) + \n  pnorm(1.96, mean=3, sd=1, \n        lower.tail=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8508304\n```\n:::\n:::\n\n\n:::\n\n:::\n\n \n\n- The left tail probability `pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE)` is essentially 0 in this case.\n- Note that this power calculation specified the value of the SE instead of the standard deviation and sample size $n$ individually.\n\n# LOB\n\n## __Sample size__ calculation for testing one mean\n\n::: {style=\"font-size: 90%;\"}\n\n* Recall in our body temperature example that $\\mu_0=98.6$ °F and $\\bar{x}= 98.25$ °F. \n    * The _p_-value from the hypothesis test was highly significant (very small).\n    * What would the sample size $n$ need to be for 80% power?\n\n* [__Calculate $n$__]{style=\"color:green\"}, \n    * given $\\alpha$, power ( $1-\\beta$ ), \"true\" alternative mean $\\mu$, and null $\\mu_0$, \n    * _assuming_ the test statistic is normal (instead of t-distribution):\n\n::: columns\n::: {.column width=\"30%\"}\n\n$$n=\\left(s\\frac{z_{1-\\alpha/2}+z_{1-\\beta}}{\\mu-\\mu_0}\\right)^2$$\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- 98.25\nmu0 <- 98.6\nsd <- 0.73\nalpha <- 0.05\nbeta <- 0.20\n(n <- (sd*(qnorm(1-alpha/2) + qnorm(1-beta)) / (mu-mu0))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 34.14423\n```\n:::\n\n```{.r .cell-code}\nceiling(n)  # always round UP to the next highest integer \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35\n```\n:::\n:::\n\n:::\n:::\n\n_We would only need a sample size of 35 for 80% power!_  \nHowever, this is an under-estimate since we used the normal instead of t-distribution.\n:::\n\n::: {style=\"font-size: 70%;\"}\nSee <http://powerandsamplesize.com/Calculators/Test-1-Mean/1-Sample-Equality>.\n:::\n\n\n## __Power__ calculation for testing one mean\n\n::: {style=\"font-size: 90%;\"}\nConversely, we can calculate how much power we had in our body temperature one-sample test, given the sample size of 130.\n\n* [__Calculate power__]{style=\"color:green\"}, \n    * given $\\alpha$, $n$, \"true\" alternative mean $\\mu$, and null $\\mu_0$, \n    * _assuming_ the test statistic is normal (instead of t-distribution)\n\n$$1-\\beta=\n\t\tP\\left(Z \\leq z-z_{1-\\alpha/2}\\right)+P\\left(Z \\leq -z-z_{1-\\alpha/2}\\right)\n\t\t\\quad ,\\quad \\text{where } z=\\frac{\\mu-\\mu_0}{s/\\sqrt{n}}$$\n\n$\\Phi$ is the probability for a standard normal distribution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- 98.25; mu0 <- 98.6; sd <- 0.73; alpha <- 0.05; n <- 130\n(z <- (mu-mu0) / (sd/sqrt(n)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -5.466595\n```\n:::\n\n```{.r .cell-code}\n(Power <- pnorm(z-qnorm(1-alpha/2)) + pnorm(-z-qnorm(1-alpha/2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9997731\n```\n:::\n:::\n\n\nIf the population mean is 98.2 instead of 98.6, we have a 99.98% chance of correctly rejecting $H_0$ when the sample size is 130.  \n\n:::\n\n\n## R package `pwr` for power analyses\n\n::: {style=\"font-size: 90%;\"}\n\n* Use `pwr.t.test` for both one- and two-sample t-tests.  \n* Specify all parameters _except for_ the one being solved for.\n\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),`  \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n\n`d` is __Cohen's d__ effect size: small = 0.2, medium = 0.5, large = 0.8\n\n::: columns\n::: {.column width=\"49%\"}\nOne-sample test (or paired t-test):\n:::\n::: {.column width=\"2%\"}\n:::\n::: {.column width=\"49%\"}\n\n$$d = \\frac{\\mu-\\mu_0}{s}$$ \n\n:::\n:::\n\n::: columns\n::: {.column width=\"49%\"}\nTwo-sample test (independent):\n:::\n::: {.column width=\"2%\"}\n:::\n::: {.column width=\"49%\"}\n\n$$d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$$\n\n:::\n:::\n\n:::\n\n::: {style=\"font-size: 80%;\"}\n* $\\bar{x}_1 - \\bar{x}_2$ is the difference in means between the two groups that one would want to be able to detect as being significant,\n* $s_{pooled}$ is the pooled SD between the two groups - often assume have same sd in each group\n\n\n* R package `pwr` for basic statistical tests\n    * <https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html>\n:::\n\n\n## `pwr`: __sample size__ for one mean test \n\n::: {style=\"font-size: 80%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\mu-\\mu_0}{s}$ \n\nSpecify all parameters _except for_ the sample size:\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\nt.n <- pwr.t.test(\n  d = (98.6-98.25)/0.73, \n  sig.level = 0.05, \n  power = 0.80, \n  type = \"one.sample\")\n\nt.n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 36.11196\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t.n)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n\n## `pwr`: __power__ for one mean test \n\n::: {style=\"font-size: 80%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\mu-\\mu_0}{s}$ \n\nSpecify all parameters _except for_ the power:\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.power <- pwr.t.test(\n  d = (98.6-98.25)/0.73, \n  sig.level = 0.05, \n  # power = 0.80, \n  n = 130,\n  type = \"one.sample\")\n\nt.power\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 130\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.9997354\n    alternative = two.sided\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t.power)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n:::\n:::\n \n\n## `pwr`: Two-sample t-test: __sample size__\n\n::: {style=\"font-size: 70%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n::: {style=\"font-size: 85%;\"}\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$\n\n__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. \n\nSpecify all parameters _except for_ the sample size:\n:::\n\n::: {style=\"font-size: 90%;\"}\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2.n <- pwr.t.test(\n  d = 2/2.3, \n  sig.level = 0.05, \n  power = 0.80, \n  type = \"two.sample\") \n\nt2.n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 21.76365\n              d = 0.8695652\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t2.n)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n:::\n\n## `pwr`: Two-sample t-test: __power__\n\n::: {style=\"font-size: 70%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n::: {style=\"font-size: 85%;\"}\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$\n\n__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. \n\nSpecify all parameters _except for_ the power:\n:::\n\n::: {style=\"font-size: 90%;\"}\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2.power <- pwr.t.test(\n  d = 2/2.3, \n  sig.level = 0.05, \n  # power = 0.80, \n  n = 22,\n  type = \"two.sample\") \n\nt2.power\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 22\n              d = 0.8695652\n      sig.level = 0.05\n          power = 0.8044288\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t2.power)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n:::\n\n## What information do we need for a power (or sample size) calculation?\n\n::: columns\n::: {.column width=\"40%\"}\nThere are 4 pieces of information:\n\n1. Level of significance $\\alpha$\n    * Usually fixed to 0.05\n1. Power\n    * Ideally at least 0.80\n1. Sample size\n1. Effect size (expected change)\n\nGiven any 3 pieces of information, we can solve for the 4th.\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(\n  d = (98.6-98.25)/0.73,\n  sig.level = 0.05, \n  # power = 0.80, \n  n=130,\n  type = \"one.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 130\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.9997354\n    alternative = two.sided\n```\n:::\n:::\n\n:::\n:::\n\n\n## More software for power and sample size calculations: PASS \n\n* PASS is a very powerful (& expensive) software that does power and sample size calculations for many advanced statistical modeling techniques.\n    * Even if you don't have access to PASS, their [documentation](https://www.ncss.com/software/pass/pass-documentation/) is very good and free online.\n    * Documentation includes formulas and references.\n    * PASS documentation for powering [means](https://www.ncss.com/software/pass/pass-documentation/#Means)\n        * One mean, paired means, two independent means\n\n* One-sample t-test documentation:\n<https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/One-Sample_T-Tests.pdf>\n\n\n## OCTRI-BERD power & sample size presentations\n\n::: {style=\"font-size: 90%;\"}\n\n* __Power and Sample Size 101__\n  * Presented by Meike Niederhausen; April 13, 2023\n  * Slides: <http://bit.ly/PSS101-BERD-April2023>\n  * [Recording](https://echo360.org/media/10f37fa6-7196-4525-bd64-6b9fcca60ac0/public)\n\n* __Power and Sample Size for Clinical Trials: An Introduction__\n  * Presented by Yiyi Chen; Feb 18, 2021\n  * Slides: http://bit.ly/PSS-ClinicalTrials\n  * [Recording](https://echo360.org/lesson/9a21deb8-258d-4305-bdc9-7effdc35e719/classroom)\n\n* __Planning a Study with Power and Sample Size Considerations in Mind__\n  * Presented by David Yanez; May 29, 2019\n  * [Slides](https://www.ohsu.edu/sites/default/files/2019-12/PowerAndSampleSize_29MAY2019.pdf)\n  * [Recording](https://echo360.org/lesson/44c9a3e9-b8ec-4042-84d8-4758cc779a1f/classroom)\n\n* __Power and Sample Size Simulations in R__\n  * Presented by Robin Baudier; Sept 21, 2023\n  * [Slides](https://www.slideshare.net/ssuser84c78e/octri-pss-simulations-in-r-seminarpdf)\n  * [Recording](https://echo360.org/media/12e6e603-13f9-4b50-bf76-787185acdfce/public)\n\n:::\n",
    "supporting": [
      "14_Power_sample_size_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}