{
  "hash": "3a2bbf08fe2b180a14e401d7299757c2",
  "result": {
    "markdown": "---\ntitle: \"Lesson 14: Power and sample size calculations\"\nsubtitle: \"TB sections 5.4\"\nauthor: \"Meike Niederhausen and Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#3070BF\"\ndate: \"11/13/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1600\n    height: 1100\n    footer: Lesson 14 Slides\n    html-math-method: mathjax\n    highlight-style: arrow\nexecute:\n  echo: true\n  freeze: auto\n---\n\n\n\n\n\n# Power and sample size calculations\n\n* Critical values & rejection region\n\n* Type I & II errors\n\n* Power\n\n* How to calculate sample size needed for a study?\n\n<hr>\n\n* Materials are from \n    * __Section 4.3.4__ Decision errors\n    * __Section 5.4__ Power calculations for a difference of means\n    * plus notes\n\n\n\n## Critical values \n\n::: {style=\"font-size: 90%;\"}\n\n* __Critical values__ are the cutoff values that determine whether a test statistic is statistically significant or not.\n* If a test statistic is greater in absolute value than the critical value, we reject $H_0$\n\n::: columns\n::: {.column width=\"49%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\n\n* Critical values are determined by \n    * the significance level $\\alpha$, \n    * whether a test is 1- or 2-sided, &\n    * the probability distribution being used to calculate the p-value (such as normal or t-distribution).\n* The critical values in the figure should look very familiar! \n    * Where have we used these before?\n\n:::\n:::\n<br>\n\n* How can we calculate the critical values using R?\n:::\n\n\n## Rejection region\n\n* If the absolute value of the test statistic is greater than the critical value, we reject $H_0$\n    * In this case the test statistic is in the __rejection region__.\n    * Otherwise it's in the nonrejection region.\n\n::: columns\n::: {.column width=\"60%\"}\n\n![[Stats & Geospatial Analysis](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html)](/img_slides/RejectionRegion.png){fig-align=\"center\"}\n\n:::\n::: {.column width=\"40%\"}\n\n* What do rejection regions look like for 1-sided tests?\n\n:::\n:::\n\n\n# Hypothesis Testing \"Errors\" \n\n![[StatisticsSolutions](https://www.statisticssolutions.com/to-err-is-human-what-are-type-i-and-ii-errors/)](/img_slides/rachnovblog-768x310.jpg){fig-align=\"center\"}\n\n\n## Justice system analogy \n\n<br><br>\n\n![[Type I and Type II Errors - Making Mistakes in the Justice System](http://www.intuitor.com/statistics/T1T2Errors.html)](/img_slides/intuitor_charts.png){fig-align=\"center\"}\n\n\n## Type I & II Errors\n\n::: columns\n::: {.column width=\"40%\"}\n\n![](/img_slides/type-i-and-type-ii-errors_chart.png){fig-align=\"center\"}\n\n::: {style=\"font-size: 90%;\"}\n\n* [$\\alpha$]{style=\"color:violet\"} = probability of making a [__Type I error__]{style=\"color:violet\"}\n    * This is the significance level (usually 0.05)\n    * Set before study starts\n* [$\\beta$]{style=\"color:green\"} = probability of making a [__Type II error__]{style=\"color:green\"}\n* Ideally we want\n    * small Type I & II errors and\n    * big power\n\n::: \n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n::: {style=\"font-size: 90%;\"}\nApplet for visualizing Type I & II errors and power: \n<https://rpsychologist.com/d3/NHST/>\n\n:::\n\n:::\n:::\n\n\n## Relationship between Type I & II errors \n\n* __Type I vs. Type II error__\n    * Decreasing P(Type I error) leads to \n        * increasing P(Type II error)\n    * We typically keep P(Type I error) = $\\alpha$ set to 0.05\n        \nFrom the applet at <https://rpsychologist.com/d3/NHST/>\n\n::: columns\n::: {.column width=\"50%\"}\n\n![](/img_slides/power_applet_screenshot_alpha05.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](/img_slides/power_applet_screenshot_alpha01.png){fig-align=\"center\"}\n:::\n:::\n\n\n## Relationship between Type II errors and power\n\n<center>__Power__ = P(correctly rejecting the null hypothesis)</center>\n\n<br>\n\n::: columns\n::: {.column width=\"49%\"}\n\n* Power is also called the\n    * true positive rate,\n    * probability of detection, or \n    * the _sensitivity_ of a test\n    \n![](/img_slides/power_applet_screenshot_alpha05.png){fig-align=\"center\"}\n\n:::\n::: {.column width=\"2%\"}\n:::\n::: {.column width=\"49%\"}\n\n* __Power vs. Type II error__\n\n    * Power = 1 - P(Type II error) = 1 - $\\beta$\n\n    * Thus as $\\beta$ = P(Type II error) decreases, the power increases\n\n    * P(Type II error) decreases as the mean of the alternative population shits further away from the mean of the null population (effect size gets bigger).\n\n    * Typically want at least 80% power; 90% power is good\n:::\n:::\n\n\n\n## Example calculating power\n\n::: {style=\"font-size: 90%;\"}\n\n* Suppose the mean of the null population is 0 ( $H_0: \\mu=0$ ) with standard error 1\n* Find the power of a 2-sided test if the actual $\\mu=3$, assuming the SE doesn't change.\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n* Power = $P($Reject $H_0$ when alternative pop is $N(3,1))$\n* When $\\alpha$ = 0.05, we reject $H_0$ when the test statistic z is at least 1.96\n* Thus for $X\\sim N(3,1)$ we need to calculate $P(X \\le -1.96) + P(X \\ge 1.96)$:\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# left tail + right tail:\npnorm(-1.96, mean=3, sd=1, lower.tail=TRUE) + pnorm(1.96, mean=3, sd=1, lower.tail=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8508304\n```\n:::\n:::\n\n\n:::\n\n::: {style=\"font-size: 70%;\"}\nThe left tail probability `pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE)` is essentially 0 in this case.\n:::\n\n::: {style=\"font-size: 90%;\"}\n* Note that this power calculation specified the value of the SE instead of the standard deviation and sample size $n$ individually.\n:::\n\n\n## __Sample size__ calculation for testing one mean\n\n::: {style=\"font-size: 90%;\"}\n\n* Recall in our body temperature example that $\\mu_0=98.6$ °F and $\\bar{x}= 98.25$ °F. \n    * The _p_-value from the hypothesis test was highly significant (very small).\n    * What would the sample size $n$ need to be for 80% power?\n\n* [__Calculate $n$__]{style=\"color:green\"}, \n    * given $\\alpha$, power ( $1-\\beta$ ), \"true\" alternative mean $\\mu$, and null $\\mu_0$, \n    * _assuming_ the test statistic is normal (instead of t-distribution):\n\n::: columns\n::: {.column width=\"30%\"}\n\n$$n=\\left(s\\frac{z_{1-\\alpha/2}+z_{1-\\beta}}{\\mu-\\mu_0}\\right)^2$$\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- 98.25\nmu0 <- 98.6\nsd <- 0.73\nalpha <- 0.05\nbeta <- 0.20\nn <- (sd*(qnorm(1-alpha/2) + qnorm(1-beta)) / (mu-mu0))^2\nn\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 34.14423\n```\n:::\n\n```{.r .cell-code}\nceiling(n)  # always round UP to the next highest integer \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35\n```\n:::\n:::\n\n:::\n:::\n\n_We would only need a sample size of 35 for 80% power!_  \nHowever, this is an under-estimate since we used the normal instead of t-distribution.\n:::\n\n::: {style=\"font-size: 70%;\"}\nSee <http://powerandsamplesize.com/Calculators/Test-1-Mean/1-Sample-Equality>.\n:::\n\n\n## __Power__ calculation for testing one mean\n\n::: {style=\"font-size: 90%;\"}\nConversely, we can calculate how much power we had in our body temperature one-sample test, given the sample size of 130.\n\n* [__Calculate power__]{style=\"color:green\"}, \n    * given $\\alpha$, $n$, \"true\" alternative mean $\\mu$, and null $\\mu_0$, \n    * _assuming_ the test statistic is normal (instead of t-distribution)\n\n$$1-\\beta=\n\t\t\\Phi\\left(z-z_{1-\\alpha/2}\\right)+\\Phi\\left(-z-z_{1-\\alpha/2}\\right)\n\t\t\\quad ,\\quad \\text{where } z=\\frac{\\mu-\\mu_0}{s/\\sqrt{n}}$$\n\n$\\Phi$ is the probability for a standard normal distribution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- 98.25; mu0 <- 98.6; sd <- 0.73; alpha <- 0.05; n <- 130\n(z <- (mu-mu0) / (sd/sqrt(n)) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -5.466595\n```\n:::\n\n```{.r .cell-code}\n(Power <- pnorm(z-qnorm(1-alpha/2)) + pnorm(-z-qnorm(1-alpha/2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9997731\n```\n:::\n:::\n\n\nIf the population mean is 98.2 instead of 98.6, we have a 99.98% chance of correctly rejecting $H_0$ when the sample size is 130.  \n\n:::\n\n\n## R package `pwr` for power analyses\n\n::: {style=\"font-size: 90%;\"}\n\n* Use `pwr.t.test` for both one- and two-sample t-tests.  \n* Specify all parameters _except for_ the one being solved for.\n\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),`  \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n\n`d` is __Cohen's d__ effect size: small = 0.2, medium = 0.5, large = 0.8\n\n::: columns\n::: {.column width=\"49%\"}\nOne-sample test (or paired t-test):\n:::\n::: {.column width=\"2%\"}\n:::\n::: {.column width=\"49%\"}\n\n$$d = \\frac{\\mu-\\mu_0}{s}$$ \n\n:::\n:::\n\n::: columns\n::: {.column width=\"49%\"}\nTwo-sample test (independent):\n:::\n::: {.column width=\"2%\"}\n:::\n::: {.column width=\"49%\"}\n\n$$d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$$\n\n:::\n:::\n\n:::\n\n::: {style=\"font-size: 80%;\"}\n* $\\bar{x}_1 - \\bar{x}_2$ is the difference in means between the two groups that one would want to be able to detect as being significant,\n* $s_{pooled}$ is the pooled SD between the two groups - often assume have same sd in each group\n\n\n* R package `pwr` for basic statistical tests\n    * <https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html>\n:::\n\n\n## `pwr`: __sample size__ for one mean test \n\n::: {style=\"font-size: 80%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\mu-\\mu_0}{s}$ \n\nSpecify all parameters _except for_ the sample size:\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\nt.n <- pwr.t.test(\n  d = (98.6-98.25)/0.73, \n  sig.level = 0.05, \n  power = 0.80, \n  type = \"one.sample\")\n\nt.n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 36.11196\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t.n)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n\n## `pwr`: __power__ for one mean test \n\n::: {style=\"font-size: 80%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\mu-\\mu_0}{s}$ \n\nSpecify all parameters _except for_ the power:\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.power <- pwr.t.test(\n  d = (98.6-98.25)/0.73, \n  sig.level = 0.05, \n  # power = 0.80, \n  n = 130,\n  type = \"one.sample\")\n\nt.power\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 130\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.9997354\n    alternative = two.sided\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t.power)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n:::\n:::\n \n\n## `pwr`: Two-sample t-test: __sample size__\n\n::: {style=\"font-size: 70%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n::: {style=\"font-size: 85%;\"}\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$\n\n__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. \n\nSpecify all parameters _except for_ the sample size:\n:::\n\n::: {style=\"font-size: 90%;\"}\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2.n <- pwr.t.test(\n  d = 2/2.3, \n  sig.level = 0.05, \n  power = 0.80, \n  type = \"two.sample\") \n\nt2.n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 21.76365\n              d = 0.8695652\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t2.n)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n:::\n\n## `pwr`: Two-sample t-test: __power__\n\n::: {style=\"font-size: 70%;\"}\n`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   \n`type = c(\"two.sample\", \"one.sample\", \"paired\"),` \n`alternative = c(\"two.sided\", \"less\", \"greater\"))`\n:::\n\n::: {style=\"font-size: 85%;\"}\n\n* `d` is __Cohen's d__ effect size: $d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}$\n\n__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. \n\nSpecify all parameters _except for_ the power:\n:::\n\n::: {style=\"font-size: 90%;\"}\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2.power <- pwr.t.test(\n  d = 2/2.3, \n  sig.level = 0.05, \n  # power = 0.80, \n  n = 22,\n  type = \"two.sample\") \n\nt2.power\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 22\n              d = 0.8695652\n      sig.level = 0.05\n          power = 0.8044288\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(t2.power)\n```\n\n::: {.cell-output-display}\n![](14_Power_sample_size_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n:::\n\n## What information do we need for a power (or sample size) calculation?\n\n::: columns\n::: {.column width=\"40%\"}\nThere are 4 pieces of information:\n\n1. Level of significance $\\alpha$\n    * Usually fixed to 0.05\n1. Power\n    * Ideally at least 0.80\n1. Sample size\n1. Effect size (expected change)\n\nGiven any 3 pieces of information, we can solve for the 4th.\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(\n  d = (98.6-98.25)/0.73,\n  sig.level = 0.05, \n  # power = 0.80, \n  n=130,\n  type = \"one.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 130\n              d = 0.4794521\n      sig.level = 0.05\n          power = 0.9997354\n    alternative = two.sided\n```\n:::\n:::\n\n:::\n:::\n\n\n## More software for power and sample size calculations: PASS \n\n* PASS is a very powerful (& expensive) software that does power and sample size calculations for many advanced statistical modeling techniques.\n    * Even if you don't have access to PASS, their [documentation](https://www.ncss.com/software/pass/pass-documentation/) is very good and free online.\n    * Documentation includes formulas and references.\n    * PASS documentation for powering [means](https://www.ncss.com/software/pass/pass-documentation/#Means)\n        * One mean, paired means, two independent means\n\n* One-sample t-test documentation:\n<https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/One-Sample_T-Tests.pdf>\n\n\n## OCTRI-BERD power & sample size presentations\n\n::: {style=\"font-size: 90%;\"}\n\n* __Power and Sample Size 101__\n  * Presented by Meike Niederhausen; April 13, 2023\n  * Slides: <http://bit.ly/PSS101-BERD-April2023>\n  * [Recording](https://echo360.org/media/10f37fa6-7196-4525-bd64-6b9fcca60ac0/public)\n\n* __Power and Sample Size for Clinical Trials: An Introduction__\n  * Presented by Yiyi Chen; Feb 18, 2021\n  * Slides: http://bit.ly/PSS-ClinicalTrials\n  * [Recording](https://echo360.org/lesson/9a21deb8-258d-4305-bdc9-7effdc35e719/classroom)\n\n* __Planning a Study with Power and Sample Size Considerations in Mind__\n  * Presented by David Yanez; May 29, 2019\n  * [Slides](https://www.ohsu.edu/sites/default/files/2019-12/PowerAndSampleSize_29MAY2019.pdf)\n  * [Recording](https://echo360.org/lesson/44c9a3e9-b8ec-4042-84d8-4758cc779a1f/classroom)\n\n* __Power and Sample Size Simulations in R__\n  * Presented by Robin Baudier; Sept 21, 2023\n  * [Slides](https://www.slideshare.net/ssuser84c78e/octri-pss-simulations-in-r-seminarpdf)\n  * [Recording](https://echo360.org/media/12e6e603-13f9-4b50-bf76-787185acdfce/public)\n\n:::\n",
    "supporting": [
      "14_Power_sample_size_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}