{
  "hash": "00596d7ecfad74305ba52cd8ab1cb556",
  "result": {
    "markdown": "---\ntitle: \"Lesson 9: Variability in estimates\"\nsubtitle: \"TB sections 4.1\"\nauthor: \"Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#3070BF\"\ndate: \"10/30/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: Lesson 9 Slides\n    html-math-method: mathjax\n    highlight-style: arrow\nexecute:\n  echo: true\n  freeze: true\n---\n\n\n\n\n## \n\n![[Artwork by @allison_horst](https://allisonhorst.com/)](../img_slides/horst_samples.png){fig-align=\"center\"}\n\n\n::: {.cell}\n<style type=\"text/css\">\n.reveal code {\n  max-height: 100% !important;\n}\n</style>\n:::\n\n\n# Learning Objectives\n\n1. Illustrate how information from several samples are connected to the population and to the sampling distribution\n\n2. Understand how the sampling distribution of the sample means relates to a sample and the population distribution \n\n3. Apply the Central Limit Theorem to approximate the sampling distribution of the sample mean\n\n## Where are we?\n\n![](../img_slides/course_map.png){fig-align=\"center\"}\n\n\n## From Lesson 1: Population vs. sample\n\n::: columns\n::: column\n\n::: red\n::: red-ttl\n(Target) Population\n:::\n::: red-cont\n* Group of interest being studied\n* Group from which the sample is selected\n  - Studies often have _inclusion_ and/or _exclusion_ criteria\n* Almost always too expensive or logistically impossible to collect data for every case in a population\n  \n:::\n:::\n:::\n\n::: column\n::: pink\n::: pink-ttl\nSample\n::: \n::: pink-cont\n* Group on which data are collected\n* Often a **small subset** of the population\n* Easier to collect data on \n* If we do it right, we might be able to answer our question about the target population\n:::\n:::\n\n:::\n:::\n\n- Goal is to get a __representative__ sample of the population: the characteristics of the sample are similar to the characteristics of the population\n    \n## Why sample statistics?\n\n- When we want to estimate features of the population\n\n  - We can use corresponding summary statistics calculated from our sample\n  - Often called [**point estimates**]{style=\"color:#EF85B3;\"} or [**sample statistics**]{style=\"color:#EF85B3;\"}\n\n \n\n- Much easier to measure statistics from our sample (Lesson 1)\n\n  - However, statistics from our sample are not exactly the same as the population measurements that we're aiming for\n  \n  - We call the population measurements [**population parameters**]{style=\"color:#C83532;\"}\n  \n \n\n- So we need to start by distinguishing between the population parameters and sample statistics\n\n\n## Population parameters vs. sample statistics\n\n::: columns\n::: {.column width=\"50%\"}\n\n[__Population parameter__]{style=\"color:#C83532;\"}\n\n- Mean: $\\mu$ (\"mu\")\n- Standard deviation: $\\sigma$ (\"sigma\")\n- Variance: $\\sigma^2$\n\n \n\n- Proportion: $p$, $\\pi$ (\"pi\")\n\n \n\n- Correlation\n\n:::\n\n::: {.column width=\"50%\"}\n[__Sample statistic (point estimate)__]{style=\"color:#EF85B3;\"}\n\n- Sample mean: $\\overline{x}$\n- Sample standard deviation: $s$\n- Sample variance: $s^2$\n\n \n\n- Sample proportion: $\\hat{p}$ (\"p-hat\")\n\n \n\n- Sample correlation coefficient: $r$\n\n:::\n:::\n\n## Poll Everywhere Question 1\n\n# Learning Objectives\n\n::: lob\n1. Illustrate how information from several samples are connected to the population and to the sampling distribution\n:::\n\n2. Understand how the sampling distribution of the sample means relates to a sample and the population distribution \n\n3. Apply the Central Limit Theorem to approximate the sampling distribution of the sample mean\n\n\n## Population \n\n![](../img_slides/samp_dist_01.png){fig-align=\"center\"}\n\n## Take one sample\n\n![](../img_slides/samp_dist_02.png){fig-align=\"center\"}\n\n## Take one sample\n\n![](../img_slides/samp_dist_03.png){fig-align=\"center\"}\n\n## Take one sample\n\n![](../img_slides/samp_dist_04.png){fig-align=\"center\"}\n\n## Take one sample\n\n![](../img_slides/samp_dist_05.png){fig-align=\"center\"}\n\n## Take one sample\n\n![](../img_slides/samp_dist_06.png){fig-align=\"center\"}\n\n## Take another sample\n\n![](../img_slides/samp_dist_07.png){fig-align=\"center\"}\n\n## Take another sample\n\n![](../img_slides/samp_dist_08.png){fig-align=\"center\"}\n\n## Take another sample\n\n![](../img_slides/samp_dist_09.png){fig-align=\"center\"}\n\n## Poll Everywhere Question 2\n\n\n## Take another sample\n\n![](../img_slides/samp_dist_10.png){fig-align=\"center\"}\n\n## Take several samples\n\n![](../img_slides/samp_dist_11.png){fig-align=\"center\"}\n\n## Difference between samples?\n\n![](../img_slides/samp_dist_12.png){fig-align=\"center\"}\n\n# Learning Objectives\n\n1. Illustrate how information from several samples are connected to the population and to the sampling distribution\n\n::: lob\n2. Understand how the sampling distribution of the sample means relates to a sample and the population distribution \n:::\n\n3. Apply the Central Limit Theorem to approximate the sampling distribution of the sample mean\n\n## More concrete example with height (1/3)\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n\n::: {.column width=\"35%\"}\n\nVariation in population ($\\sigma$):\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu = 65 \\text{ inches}$$\n$$ \\sigma = 3 \\text{ inches}$$\n:::\n\n::: {.column width=\"30%\"}\n\n:::\n\n::: {.column width=\"35%\"}\n\n:::\n:::\n\n\n\n## More concrete example with height (2/3)\n\n::: columns\n\n::: {.column width=\"35%\"}\nVariation in population ($\\sigma$):\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu = 65 \\text{ inches}$$\n$$ \\sigma = 3 \\text{ inches}$$\n:::\n\n::: {.column width=\"27%\"}\n\nVariation within samples ($s$):\n\n![](../img_slides/heights_samples.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"35%\"}\n\n:::\n:::\n\n\n\n## More concrete example with height (3/3)\n\n::: columns\n\n::: {.column width=\"35%\"}\n\nVariation in population ($\\sigma$):\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu = 65 \\text{ inches}$$\n$$ \\sigma = 3 \\text{ inches}$$\n:::\n\n::: {.column width=\"27%\"}\n\nVariation within samples ($s$):\n\n![](../img_slides/heights_samples.png){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"35%\"}\n\nVariation between samples ($SE$):\n\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu_{\\overline{X}} = 65.002 \\text{ inches}$$\n$$ SE = 0.421 \\text{ inches}$$\n\n:::\n:::\n\n## Sampling Distribution of Sample Means\n\n::: columns\n\n::: {.column width=\"65%\"}\n\n- The __[sampling distribution]{style=\"color:#E75B5C\"}__ is the distribution of sample means calculated from repeated random samples of _the same size_ from the same population\n\n- It is useful to think of a **particular sample statistic** as\nbeing **drawn from a**  [**sampling distribution**]{style=\"color:#E75B5C\"}\n\n    - So the red sample with $\\overline{x} = 65.1$ is **just one sample mean** in the **sampling distribution**\n\n:::\n\n::: {.column width=\"35%\"}\n\nVariation between samples ($SE$):\n\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu_{\\overline{X}} = 65.002 \\text{ inches}$$\n$$ SE = 0.421 \\text{ inches}$$\n\n:::\n:::\n\n## For following Poll Everywhere Question\n\nHow are the center, shape, and spread similar and/or different?\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-9-1.png){width=864}\n:::\n:::\n\n\n:::\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-10-1.png){width=864}\n:::\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 3\n\n## Okay, but in real life we only have one sample...?\n\n- In a study, conclusions about a population parameter **must be drawn from the data collected from a single sample**\n\n \n\n- The [**sampling distribution**]{style=\"color:#E75B5C\"} of $\\overline{X}$ is a **theoretical concept**\n\n    - Obtaining repeated samples by conducting a study many times is not possible\n    \n \n\n- **Not feasible** to calculate the population mean $\\mu$ by finding the mean of the [**sampling distribution**]{style=\"color:#E75B5C\"} for $\\overline{X}$\n\n \n\n- In the next lesson on confidence intervals, we'll see what kind of statements we can make about the population mean from a single sample\n\n# Learning Objectives\n\n1. Illustrate how information from several samples are connected to the population and to the sampling distribution\n\n2. Understand how the sampling distribution of the sample means relates to a sample and the population distribution \n\n::: lob\n3. Apply the Central Limit Theorem to approximate the sampling distribution of the sample mean\n:::\n\n## What happens if we collect more or less samples? {visibility=\"hidden\"}\n\nFor samples that measure 50 people's heights ($n=50$), we can look at the [**sampling distribution**]{style=\"color:#E75B5C\"} for...\n\n::: columns\n::: column\n20 samples:\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\n::: column\n100 samples:\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n\n::: column\n1,000 samples:\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n:::\n\n::: column\n10,000 samples:\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n\n## The Central Limit Theorem (CLT) \n\n- If a sample consists of **at least 30 independent observations**, then the [**sampling distribution**]{style=\"color:#E75B5C\"} of the sample mean is **approximated by a normal model**\n\n- Aka, for **\"large\" sample sizes** ( $n\\geq 30$ ),\n    * The [**sampling distribution**]{style=\"color:#E75B5C\"} of the sample mean can be approximated by a __normal distribution__,with \n      * Mean equal to the population mean value $\\mu$\n      * Standard deviation $\\frac{\\sigma}{\\sqrt{n}}$\n      \n- This is **regardless of the original sample is from a different distribution**\n  - For example, if we count the number of heads in 50 coin flips, and do this for many samples, then our [**sampling distribution**]{style=\"color:#E75B5C\"} will be Normally distributed around $n\\cdot p = 50 \\cdot 0.5= 25$\n  \n\n## Other cases for normal approximation \n* For **small sample sizes**, if the **population is known to be normally distributed**, then\n    * The [**sampling distribution**]{style=\"color:#E75B5C\"} of the sample mean is a __normal distribution__, with \n      * Mean equal to the population mean value $\\mu$, and \n      * Standard deviation $\\frac{\\sigma}{\\sqrt{n}}$\n      \n- Not technically the Central Limit Theorem, but [**sampling distribution**]{style=\"color:#E75B5C\"} approximated using same Normal distribution \n  \n## Sampling Distribution of Sample Means (with the CLT)\n\n::: columns\n\n::: {.column width=\"65%\"}\n\n- The __[sampling distribution]{style=\"color:#E75B5C\"}__ is the distribution of sample means calculated from repeated random samples of _the same size_ from the same population\n\n- It is useful to think of a **particular sample statistic** as\nbeing **drawn from a**  [**sampling distribution**]{style=\"color:#E75B5C\"}\n\n    - So the red sample with $\\overline{x} = 65.1$ is **just one sample mean** in the **sampling distribution**\n\n::: blue\n::: blue-ttl\nWith CLT and $\\overline{X}$ as the RV for the [**sampling distribution**]{style=\"color:#E75B5C\"}\n:::\n::: blue-cont\n- **Theoretically** (using only population values): $\\overline{X} \\sim \\text{Normal} \\big(\\mu_{\\overline{X}} = \\mu, \\sigma_{\\overline{X}}= SE = \\frac{\\sigma}{\\sqrt{n}} \\big)$\n- **In real use** (using sample values for SE): $\\overline{X} \\sim \\text{Normal} \\big(\\mu_{\\overline{X}} = \\mu, \\sigma_{\\overline{X}}= SE = \\frac{s}{\\sqrt{n}} \\big)$\n:::\n:::\n:::\n\n::: {.column width=\"35%\"}\n\nVariation between samples ($SE$):\n\n\n \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n$$ \\mu_{\\overline{X}} = 64.996 \\text{ inches}$$\n$$ SE = 0.291 \\text{ inches}$$\n\n:::\n:::\n\n## Let's apply the CLT to our sampling distribution when n = 50 (1/2)\n::: columns\n::: {.column width=\"50%\"}\n:::\n\n::: {.column width=\"50%\"}\nCLT tells us that we can model the sampling distribution of mean heights using a normal distribution:\n:::\n:::\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\n:::\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n\n## Let's apply the CLT to our sampling distribution when n = 50 (2/2)\n::: columns\n::: {.column width=\"70%\"}\nMean and SD of **population**:\n$$ \\mu = 65 \\text{ inches} \\text{,  } \\sigma = 3 \\text{ inches}$$\n\nFrom the CLT, we can figure out the **theoretical** mean and standard deviation of our sampling distribution:\n\n$$ \\mu = 65 \\text{ inches}$$\n$$ SE = \\frac{\\sigma}{\\sqrt{n}} \\text{ inches} = \\frac{3}{\\sqrt{50}} \\text{ inches} = 0.424 \\text{ inches}$$\n\nI simulated the data, so I can calculate mean and SE of the sampling distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(sample_mean = mean(means50$means))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 65.00198\n```\n:::\n\n```{.r .cell-code}\n(sample_se = sd(means50$means))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4212266\n```\n:::\n:::\n\n:::\n::: {.column width=\"30%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n## Applying the CLT (1/2)\n\n::: example\n::: ex-ttl\nExample 1\n:::\n::: ex-cont\nFor a random sample of 100 people, what is the probability that their mean height is greater than 65 inches? We happen to know the population mean is 64 inches and population standard deviation is 4 inches.\n:::\n:::\n\n1. Make sure that the number of individuals in the sample is greater than 30: $100 > 30$, so we can use the CLT\n2. Find the mean and standard error for our sampling distribution: $$\\mu_{\\overline{X}}=64$$\n$$SE = \\frac{\\sigma}{\\sqrt{n}}= \\frac{4}{\\sqrt{100}}= 0.4 \\text{ inches}$$\n$$ \\overline{X} \\sim \\text{Normal} (64, 0.4)$$\n\n## Applying the CLT (2/2)\n\n::: example\n::: ex-ttl\nExample 1\n:::\n::: ex-cont\nFor a random sample of 100 people, what is the probability that their mean height is greater than 65 inches? We happen to know the population mean is 64 inches and population standard deviation is 4 inches.\n:::\n:::\n\n3. Calculate the probability from a Normal distribution: $P(H \\geq 65)$\n\n::: columns\n::: column\n\n::: {.cell}\n::: {.cell-output-display}\n![](09_Variability_files/figure-revealjs/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n:::\n\n::: column\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 65, mean = 64, sd = 0.4, \n      lower.tail = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.006209665\n```\n:::\n:::\n\n\nThe probability that a 100-person sample has a mean of 65 or greater is 0.006. Makes me question if our sample really came from the population...\n:::\n:::\n\n## Check out this video explanation of CLT\n\n* [Bunnies, Dragons and the 'Normal' World: Central Limit Theorem]{style=\"color:#BF396F\"}\n    * Creature Cast from the New York Times\n    * [https://www.youtube.com/watch?v=jvoxEYmQHNM&feature=youtu.be](https://www.youtube.com/watch?v=jvoxEYmQHNM&feature=youtu.be)\n\n![](../img_slides/CLT_video_preview.png){fig-align=\"center\" width=80%}\n\n## Summary Review: Point Estimate Terminology\n\n- **Population mean**: $\\mu$\n- **Population standard deviation**: $\\sigma$\n- **Sample mean**: $\\overline{x}$\n- **Sample standard deviation**: $s$\n- **Sampling distribution**: Distribution of sample means for repeated samples.\n  - Use $\\overline{X}$ as the RV for this distribution\n  - $\\overline{X} \\sim \\text{Normal} \\bigg(\\mu_{\\overline{X}} = \\mu, \\sigma_{\\overline{X}}= SE = \\frac{s}{\\sqrt{n}} \\bigg)$\n- **Standard error (SE)**: The standard deviation of the sampling distribution.\n    - Formula: $SE = \\frac{s}{\\sqrt{n}}$\n",
    "supporting": [
      "09_Variability_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}