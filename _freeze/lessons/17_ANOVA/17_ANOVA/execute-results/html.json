{
  "hash": "3092412e92fdf96455ffe93cfff5eeca",
  "result": {
    "markdown": "---\ntitle: \"Lesson 17: Comparing Means with ANOVA\"\nsubtitle: \"TB sections 5.5\"\nauthor: \"Meike Niederhausen and Nicky Wakim\"\ntitle-slide-attributes:\n    data-background-color: \"#3070BF\"\ndate: \"12/2/2024\"\nformat: \n  revealjs:\n    theme: \"../simple_NW.scss\"\n    chalkboard: true\n    slide-number: true\n    show-slide-number: all\n    width: 1955\n    height: 1100\n    footer: Lesson 17 Slides\n    html-math-method: mathjax\n    highlight-style: arrow\nexecute:\n  echo: true\n  freeze: auto\n---\n\n\n\n\n# Learning Objectives\n\n1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).\n\n2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.\n\n3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. \n\n4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.\n\n\n::: {.cell}\n<style type=\"text/css\">\n.reveal code {\n  max-height: 100% !important;\n}\n.reveal pre.sourceCode code {\n  max-height: 100% !important;\n}\n</style>\n:::\n\n\n## Where are we?\n\n![](../img_slides/course_map.png){fig-align=\"center\"}\n\n\n## A little while ago...\n\n-   We looked at inference for a **single mean**\n-   We looked at inference for a difference in **means from two independent samples**\n\n \n\n-   If there are two groups, we could see if they had different means by testing if the difference between the means were the same (null) or different (alternative)\n\n \n\n-   What happens when we want to compare two **or more** groups' means?\n\n    -   Can no longer rely on the difference in means\n    -   Need a new method to make inference (ANOVA or Linear Regression!)\n\n# Learning Objectives\n\n::: lob\n1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).\n:::\n\n2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.\n\n3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. \n\n4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.\n\n## From Lesson 8: Data visualization\n\n- Study investigating whether ACTN3 genotype at a particular location (residue 577) is associated with change in muscle function\n\n \n\n- **Categorical variable:** genotypes (CC, TT, CT)\n\n \n\n- **Numeric variable:** Muscle function, measured as percent change in non-dominant arm strength\n\n \n\n- We can start the investigation by plotting the relationship\n\n## From Lesson 8: Side-by-side boxplots with data points\n\n- We can look at the boxplot of percent change for each genotype **with points shown so we can see the distribution of observations better**\n\n::: columns\n::: {.column width=\"53%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"7-11\"}\nggplot(data = famuss, \n       aes(x = actn3.r577x, \n           y = ndrm.ch)) + \n  geom_boxplot() + \n  labs(x = \"ACTN3 genotype\", \n       y = \"Percent Change in Non-Dominant Arm Strength\")  +\n  geom_jitter(aes(color = actn3.r577x), \n    alpha = 0.3,      \n    show.legend = FALSE,      \n    position = position_jitter(     \n      height = 0.4))      \n```\n:::\n\n\n:::\n::: {.column width=\"47%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/box_sbs_jitter_out-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n## From Lesson 8: Ridgeline plot \n\n- Overlapped densities were easy enough to see with 3 genotypes\n- If you have **many categories**, a ridgeline plot might make it easier to see\n\n::: columns\n::: {.column width=\"53%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"6-7\"}\nlibrary(ggridges)\nggplot(data = famuss, \n       aes(y = actn3.r577x, \n           x = ndrm.ch, \n           fill = actn3.r577x)) +\n  geom_density_ridges(alpha = 0.3, \n          show.legend = FALSE) +      \n  labs(x = \"Percent Change in Non-Dominant Arm Strength\",\n       y = \"ACTN3 genotype\",\n       title = \"Strength change by genotype\")       \n```\n:::\n\n:::\n::: {.column width=\"47%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/density_ridge_out-1.png){width=720}\n:::\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 1\n\n\n# Learning Objectives\n\n1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).\n\n::: lob\n2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.\n:::\n\n3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. \n\n4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.\n\n## Comparing means\n\n::: columns\n::: {.column width=\"40%\"}\nWhether or not two means are significantly different depends on:\n\n* How far apart the __means__ are\n* How much __variability__ there is within each group\n\n__[Questions:]{style=\"color:#C83532\"}__  \n\n* How to measure variability __between__ groups?\n* How to measure variability __within__ groups?\n* How to compare the two measures of variability?\n* How to determine significance?\n:::\n\n::: {.column width=\"60%\"}\n![](../img_slides/toyANOVA.png)\n:::\n:::\n\n## Generic ANOVA table\n\n![](../img_slides/anova_table.png){fig-align=\"center\" height=7in}\n\n## ANOVA: Analysis of Variance  {.nostretch}\n\n__ANOVA__ compares the variability between groups to the variability within groups \n\n\n![](../img_slides/anova_total_variability.png){fig-align=\"center\" height=1.75in}\n\n::: columns\n::: {.column width=33%}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=33%}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=33%}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n:::\n:::\n\n## ANOVA: Analysis of Variance  {.nostretch}\n\n__Analysis of Variance (ANOVA)__ compares the variability between groups to the variability within groups \n\n![](../img_slides/anova_total_variability.png){fig-align=\"center\" height=2in}\n\n\n$$\\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(x_{ij} -\\bar{x})^2 \\ \\ \n= \\ \\sum_{i = 1}^k n_i(\\bar{x}_{i}-\\bar{x})^2 \\ \\ \n+ \\ \\ \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(x_{ij}-\\bar{x}_{i})^2$$\n\n\n![](../img_slides/anova_SS_total.png){fig-align=\"center\" height=2in}\n\n\n\n\n## Notation\n\n::: columns\n::: {.column width=\"30%\"}\n\n* _k_ groups\n* $n_i$ observations in each of the _k_ groups\n* Total sample size is $N=\\sum_{i=1}^{k}n_i$\n* $\\bar{x}_{i}$ = mean of observations in group _i_\n* $\\bar{x}$ = mean of _all_ observations\n* $s_{i}$ = sd of observations in group _i_\n* $s$ = sd of _all_ observations\n\n:::\n\n::: {.column width=\"70%\"}\n\n| Observation | *i* = 1       | *i* = 2       | *i* = 3       | $\\ldots$ | *i* = *k*     | overall   |\n|:------------|:-------------:|:-------------:|:-------------:|:--------:|:-------------:|:---------:|\n| *j* = 1     | $x_{11}$      | $x_{21}$      | $x_{31}$      | $\\ldots$ | $x_{k1}$      |           |\n| *j* = 2     | $x_{12}$      | $x_{22}$      | $x_{32}$      | $\\ldots$ | $x_{k2}$      |           |\n| *j* = 3     | $x_{13}$      | $x_{23}$      | $x_{33}$      | $\\ldots$ | $x_{k3}$      |           |\n| *j* = 4     | $x_{14}$      | $x_{24}$      | $x_{34}$      | $\\ldots$ | $x_{k4}$      |           |\n| $\\vdots$    | $\\vdots$      | $\\vdots$      | $\\vdots$      | $\\ddots$ | $\\vdots$      |           |\n| *j* = $n_i$ | $x_{1n_1}$      | $x_{2n_2}$      | $x_{3n_3}$      | $\\ldots$ | $x_{kn_k}$      |           |\n| Means       | $\\bar{x}_{1}$ | $\\bar{x}_{2}$ | $\\bar{x}_{3}$ | $\\ldots$ | $\\bar{x}_{k}$ | $\\bar{x}$ |\n| Variance    | ${s}^2_{1}$   | ${s}^2_{2}$   | ${s}^2_{3}$   | $\\ldots$ | ${s}^2_{k}$   | ${s}^2$   |\n\n:::\n:::\n\n\n\n\n## Total Sums of Squares (SST)\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n:::\n::: {.column width=\"60%\"}\n\nTotal Sums of Squares:\n\n$$SST = \\sum_{i = 1}^k \\sum_{j = 1}^{n_i}(x_{ij} -\\bar{x})^2 = (N-1)s^2$$\n\n* where \n    * $N=\\sum_{i=1}^{k}n_i$ is the total sample size and\n    * $s^2$ is the grand standard deviation of all the observations\n\n* This is the sum of the squared differences between each observed $x_{ij}$ value and the *grand mean*, $\\bar{x}$. \n\n* That is, it is the total deviation of the $x_{ij}$'s from the grand mean. \n\n:::\n:::\n\n## Sums of Squares due to Groups (SSG)\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n::: {.column width=\"60%\"}\nSums of Squares due to Groups:\n\n$$SSG = \\sum_{i = 1}^k n_i(\\bar{x}_{i}-\\bar{x})^2$$\n\n* This is the sum of the squared differences between each *group* mean, $\\bar{x}_{i}$, and the *grand mean*, $\\bar{x}$. \n\n* That is, it is the deviation of the group means from the grand mean.\n\n* Also called the Model SS, or $SS_{model}.$\n\n:::\n:::\n\n## Sums of Squares Error (SSE)\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n::: {.column width=\"60%\"}\nSums of Squares Error:\n\n$$SSE = \\sum_{i = 1}^k\\sum_{j = 1}^{n_i}(x_{ij}-\\bar{x}_{i})^2 = \\sum_{i = 1}^k(n_i-1)s_{i}^2$$\nwhere $s_{i}$ is the standard deviation of the $i^{th}$ group\n\n* This is the sum of the squared differences between each observed $x_{ij}$ value and its group mean $\\bar{x}_{i}$. \n\n* That is, it is the deviation of the $x_{ij}$'s from the predicted ndrm.ch by group.\n\n* Also called the residual sums of squares, or $SS_{residual}.$\n\n:::\n:::\n\n## Poll Everywhere Question 2\n\n## ANOVA table to hypothesis test?\n\n- Okay, so how do we use all these types of variability to run a test? \n- How do we determine, statistically, if the groups have different means or not?\n\n![](../img_slides/anova_table.png){fig-align=\"center\"}\n\n- Answer: We use the F-statistic in a hypothesis test!\n\n# Learning Objectives\n\n1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).\n\n2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.\n\n::: lob\n3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. \n:::\n\n4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.\n\n## Thinking about the F-statistic\n\n::: columns\n::: {.column width=\"49.5%\"}\n__[If the groups are actually different, then which of these is more accurate?]{style=\"color:#C83532\"}__\n\n1. **The variability between groups should be higher than the variability within groups**\n1. The variability within groups should be higher than the variability between groups\n\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"49.5%\"}\n__[If there really is a difference between the groups, we would expect the F-statistic to be which of these: ]{style=\"color:#C83532\"}__\n\n1. **Higher than we would observe by random chance**\n1. Lower than we would observe by random chance\n\n:::\n:::\n\n![](../img_slides/hypothetical_disability_data_v2.png){fig-align=\"center\"}\n\n\n## The F-statistic\n\n- F-statistic represents the standardized ratio of variability between groups to the variability within the groups\n\n$$F_{stat} = \\dfrac{MSG}{MSE}$$\n\n- F is larger when the variability between groups is larger than variability within groups\n\n\n## The F-distribution\n\n::: columns\n::: {.column width=\"45%\"}\n\n* The F-distribution is skewed right\n* The F-distribution has __[two different degrees of freedom]{style=\"color:#BF396F\"}__:\n    * one for the [numerator]{style=\"color:#BF396F\"} of the ratio [(k – 1)]{style=\"color:#BF396F\"} and \n    * one for the [denominator (N – k)]{style=\"color:#BF396F\"}\n\n* [$p$-__value__]{style=\"color:#459B99\"}  \n    * $P(F > F_{stat})$\n    * is always the __[upper tail]{style=\"color:#459B99\"}__\n    * (the area as extreme or more extreme)\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_ANOVA_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n:::\n:::\n\n## Poll Everywhere Question 3\n\n\n# Learning Objectives\n\n1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).\n\n2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.\n\n3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. \n\n::: lob\n4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.\n:::\n\n## Reference: Steps in a Hypothesis Test\n\n1.  Check the [**assumptions**]{style=\"color:#3070BF\"}\n\n2.  Set the [**level of significance**]{style=\"color:#3070BF\"} $\\alpha$\n\n3.  Specify the [**null**]{style=\"color:#3070BF\"} ( $H_0$ ) and [**alternative**]{style=\"color:#3070BF\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#3070BF\"}\n\n    1.  In symbols\n    2.  In words\n    3.  ~~Alternative: one- or two-sided?~~\n\n4.  Calculate the [**test statistic**]{style=\"color:#3070BF\"}.\n\n5.  Calculate the [**p-value**]{style=\"color:#3070BF\"} based on the observed test statistic and its sampling distribution\n\n6.  Write a [**conclusion**]{style=\"color:#3070BF\"} to the hypothesis test\n\n    1.  Do we reject or fail to reject $H_0$?\n    2.  Write a conclusion in the context of the problem\n\n## Step 1: Check assumptions\n\nThe sampling distribution is an __F-distribution__, if...\n\n- Sample sizes in each group group are large (each $n \\ge 30$) \n    * OR the data are relatively normally distributed in each group\n- Variability is \"similar\" in all group groups:\n    * Is the within group variability about the same for each group?\n    * As a rough rule of thumb, this condition is _violated if the standard deviation of one group is more than double the standard deviation of another group_\n\n## Step 1: Check assumptions\n\n- Use R to check both assumptions in our example\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenotype_groups <- famuss %>% \n  group_by(actn3.r577x) %>% \n  summarise(count = n(), \n            SD = sd(ndrm.ch))\ngenotype_groups\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  actn3.r577x count    SD\n  <fct>       <int> <dbl>\n1 CC            173  30.0\n2 CT            261  33.2\n3 TT            161  35.7\n```\n:::\n:::\n\n\n- Counts in each group are greater than 30!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmax(genotype_groups$SD) / min(genotype_groups$SD)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.191455\n```\n:::\n:::\n\n\n- Variability in one group vs. another is no more than 1.2 times!\n\n## Step 3: Specify Hypotheses\n\n::::::::::: columns\n:::::: column\n::::: blue\n::: blue-ttl\nGeneral hypotheses\n:::\n\n::: blue-cont\nTo test for a difference in means across _k_ groups:\n\n\\begin{align}\nH_0 &: \\mu_1 = \\mu_2 = ... = \\mu_k\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j \\text{ for } i \\neq j\n\\end{align}\n:::\n:::::\n::::::\n\n:::::: column\n::::: pink\n::: pink-ttl\nHypotheses test for example\n:::\n\n::: pink-cont\n\\begin{align}\nH_0 &: \\mu_{CC} = \\mu_{CT} = \\mu_{TT}\\\\\n\\text{vs. } H_A&: \\text{At least one pair } \\mu_i \\neq \\mu_j \\text{ for } i \\neq j\n\\end{align}\n:::\n:::::\n::::::\n:::::::::::\n\n## Step 4-5: Find the test statistic and p-value\n\n- Our test statistic is an F-statistic\n    - F-statistic: measurement of the ratio of variability between groups to variability within groups\n\n \n\n- Our F-statistic follows an F-distribution\n    - Which is why we cannot use something like the Z-distribution nor T-distribution\n    \n \n\n- So we'll need to find the F-statistic and its corresponding p-value using an F-distribution\n    \n\n## Step 4-5: Find the test statistic and p-value\n\n* There are several options to run an ANOVA model (aka calculate F-statistic and p-value)\n* Two most common are `lm` and `aov`\n    * `lm` = linear model; will be using frequently in BSTA 512\n\n::: columns\n::: column\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(ndrm.ch ~ actn3.r577x, \n    data = famuss) %>% anova()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: ndrm.ch\n             Df Sum Sq Mean Sq F value  Pr(>F)  \nactn3.r577x   2   7043  3521.6  3.2308 0.04022 *\nResiduals   592 645293  1090.0                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n:::\n\n::: column\n\n::: {.cell}\n\n```{.r .cell-code}\naov(ndrm.ch ~ actn3.r577x, \n    data = famuss) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)  \nactn3.r577x   2   7043    3522   3.231 0.0402 *\nResiduals   592 645293    1090                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n:::\n:::\n\n## Step 6: Conclusion\n\n\\begin{align}\nH_0 &: \\mu_{CC} = \\mu_{CT} = \\mu_{TT}\\\\\n\\text{vs. } H_A&: \\text{At least one pair} \\mu_i \\neq \\mu_j \\text{ for } i \\neq j\n\\end{align}\n\n\n-   Recall the $p$-value = 0.0402\n-   Use $\\alpha$ = 0.05\n-   Do we reject or fail to reject $H_0$?\n\n__Conclusion statement__:\n\n* There is sufficient evidence that at least one of the genotype groups has a change in arm strength statistically different from the other groups. ( $p$-value =0.0402)\n\n## Final note\n\n::: columns\n::: column\n- Recall, visually the three looked pretty close\n\n- This is the case that I would also do some work to report the means and standard deviations of each genotype's percent change in non-dominant arm strength. \n:::\n::: column\n\n::: {.cell}\n\n```{.r .cell-code}\nfamuss %>% \n  group_by(actn3.r577x) %>% \n  summarise(count = n(),\n            mean = mean(ndrm.ch),\n            SD = sd(ndrm.ch))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  actn3.r577x count  mean    SD\n  <fct>       <int> <dbl> <dbl>\n1 CC            173  48.9  30.0\n2 CT            261  53.2  33.2\n3 TT            161  58.1  35.7\n```\n:::\n:::\n\n:::\n:::\n\n__Revised conclusion statement__:\n\n* For people with CC genotype then mean percent change in arm non-dominant arm strength was 48.9% (SD = 30%). For CT, mean percent change was 53.2% (SD = 33.2%). For TT, mean percent change was 58.1% (SD = 35.7%). There is sufficient evidence that at least one of the genotype groups has a change in arm strength statistically different from the other groups. ( $p$-value =0.0402)\n\n",
    "supporting": [
      "17_ANOVA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}