---
title: "Lesson 13: Inference for difference in means from two independent samples and Power"
subtitle: "TB sections 5.3"
author: "Meike Niederhausen and Nicky Wakim"
title-slide-attributes:
    data-background-color: "#3070BF"
date: "10/2/2024"
format: 
  revealjs:
    theme: "../simple_NW.scss"
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Lesson 13 Slides
    html-math-method: mathjax
    highlight-style: arrow
execute:
  echo: true
  freeze: auto
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) # new-ish
library(here) # new-ish
library(pwr) # NEW!!

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

set.seed(456)
```

## MoRitz's tip of the day

Add tabbed sections to your html file using `tabset`.

::: panel-tabset

### First tab

* You can make subsections appear as different tabs in your html file.
* This is the first tab.
* It was created by adding `::: panel-tabset` right above the subsection `### First tab` ([see the code file]{style="color:green"}). 
* Look up to the right of where it says "First tab," and you will see a second tab with the creative name "Second tab."
* If you are viewing the html output of this file, you can click on the different tabs to see what's in them.
* To stop new tabs from being created, close off the original `::: panel-tabset` command with `:::` at the end.
    * In the source code file, you will see the `:::` at the end of the `### Read up on tabsets` tab.


### Second tab

* Welcome to the second tab! 


![](/img_slides/mimi_normal_IMG_4244.png){fig-align="center"}

### Read up on tabsets

* You can read up more about creating tabs at
  * <https://quarto.org/docs/interactive/layout.html#tabset-panel>

```{=html}
<iframe width="800" height="300" src="https://quarto.org/docs/interactive/layout.html#tabset-panel" title="Webpage example"></iframe>
```

If you are reading the source code file, the next line contains `:::`, which closes the tabsets. 
:::


## Where are we?

<br>
<br>

![](/img_slides/flowchart_511_continuous.png){fig-align="center"}

## Where are we? Continuous outcome zoomed in

<br>
<br>

![](/img_slides/flowchart_only_continuous.jpg){fig-align="center"}


## Where are we?

::: {style="font-size: 90%;"}
CI's and hypothesis tests for different scenarios:

$$\text{point estimate} \pm z^*(or~t^*)\cdot SE,~~\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$

Day | Book | Population <br> parameter | Symbol | Point estimate | Symbol | SE
--|--|--|--|--|--|--
10 | 5.1 | Pop mean | $\mu$ | Sample mean | $\bar{x}$ | $\frac{s}{\sqrt{n}}$
10 | 5.2 | Pop mean of paired diff | $\mu_d$ or $\delta$ | Sample mean of paired diff | $\bar{x}_{d}$  | **$\frac{s_d}{\sqrt{n}}$**
11 | 5.3 | [Diff in pop <br> means]{style="color:green"} | [$\mu_1-\mu_2$]{style="color:green"} | [Diff in sample <br> means]{style="color:green"} | [$\bar{x}_1 - \bar{x}_2$]{style="color:green"}  | [**???**]{style="color:red"}
12 | 8.1 | Pop proportion | $p$ | Sample prop | $\widehat{p}$  |
12 | 8.2 | Diff in pop <br> proportions | $p_1-p_2$ | Diff in sample <br> proportions | $\widehat{p}_1-\widehat{p}_2$ |

:::


## Goals for today 

### 2-sample t-test (Section 5.3)

* Statistical inference for difference in means from 2 independent samples
    1. What are $H_0$ and $H_a$?
    
    1. What is the SE for $\bar{x}_1 - \bar{x}_2$?
    
    1. Hypothesis test
    
    1. Confidence Interval
    
    1. Run test in R - using long vs. wide data
    
    1. Satterthwaite's df
    
    1. Pooled SD

### Power and sample size (4.3.4, 5.4, plus notes)

* Critical values & rejection region
* Type I & II errors
* Power
* How to calculate sample size needed for a study?


## Examples of designs with two independent samples

* Any study where participants are randomized to a control and treatment group

* Study where create two groups based on whether they were exposed or not to some condition (can be observational)

*  Book: "Does treatment using embryonic stem cells (ESCs) help improve heart function following a heart attack?"

*  Book: "Is there evidence that newborns from mothers who smoke have a different average birth weight than newborns from mothers who do not smoke?"


* _The key is that the data from the two groups are independent of each other._


## Steps in a Hypothesis Test

1. Set the __[level of significance]{style="color:darkorange"}__ $\alpha$

1. Specify the __[null]{style="color:darkorange"}__ ( $H_0$ ) and __[alternative]{style="color:darkorange"}__ ( $H_A$ ) __[hypotheses]{style="color:darkorange"}__
    1. In symbols
    1. In words
    1. Alternative: one- or two-sided?

1. Calculate the __[test statistic]{style="color:darkorange"}__. 

1. Calculate the __[p-value]{style="color:darkorange"}__ based on the observed test statistic and its sampling distribution

1. Write a __[conclusion]{style="color:darkorange"}__ to the hypothesis test
    1. Do we reject or fail to reject $H_0$?
    1. Write a conclusion in the context of the problem


## Does caffeine increase finger taps/min (on average)?

__Study Design__:

::: {style="font-size: 85%;"}
* 20 male college students students were trained to tap their fingers at a rapid rate.
* Each then drank 2 cups of coffee (double-blind)
    * __Control__ group: decaf
    * __Caffeine__ group: ~ 200 mg caffeine 
* After 2 hours, students were tested.
* __Taps/minute__ recorded
:::

::: {style="font-size: 70%;"}
Hand, David J.; Daly, Fergus; McConway, K.; Lunn, D. and Ostrowski, E. (1993). [A handbook of small data sets](https://www.crcpress.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780412399206). London, U.K.: Chapman and Hall.
:::

::: {style="font-size: 85%;"}
* Load the data from the csv file `CaffeineTaps.csv`
* The code below is for when the data file is in a folder called `data` that is in your R project folder (your working directory)
:::

```{r}
#| fig.width: 10
#| fig.height: 6
CaffTaps <- read_csv(here::here("data", "CaffeineTaps.csv"))

glimpse(CaffTaps)
```



## EDA: Explore the finger taps data
::: columns
::: {.column width="47%"}
Dotplot of taps/minute stratified by group

```{r}
#| fig.width: 10
#| fig.height: 7
ggplot(CaffTaps, aes(x=Taps)) +
  geom_dotplot() +
  facet_wrap(vars(Group), ncol=1)
```
:::

::: {.column width="53%"}

Summary statistics stratified by group

```{r}
# get_summary_stats() from rstatix package
sumstats <- CaffTaps %>% 
  group_by(Group) %>% 
  get_summary_stats(type = "mean_sd") 
sumstats %>% gt()
diff(sumstats$mean)
```

:::
:::



## Step 2: Null & Alternative Hypotheses 

* __Question__: Is there evidence to support that drinking caffeine increases the number of finger taps/min?

::: columns
::: {.column width="60%"}
Null and alternative hypotheses in __words__

*Include as much context as possible*

<br>

* $H_0$: The population difference in mean finger taps/min between the caffeine and control groups is ... 

* $H_A$: The population difference in mean finger taps/min between the caffeine and control groups is ...
:::

::: {.column width="40%"}
Null and alternative hypotheses in __symbols__

\begin{align}
H_0:& \mu_{caff} - \mu_{ctrl} = \\
H_A:& \mu_{caff} - \mu_{ctrl} \\
\end{align}
:::
:::



## Step 3: Test statistic (part 1)

Recall that in general the test statistic has the form:


$$\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$
Thus, for a two sample independent means test, we have:

$$\text{test statistic} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{SE_{\bar{x}_1 - \bar{x}_2}}$$

* What is the formula for $SE_{\bar{x}_1 - \bar{x}_2}$?
* What is the probability distribution of the test statistic?
* What assumptions need to be satisfied?




## What distribution does $\bar{X}_1 - \bar{X}_2$ have?
::: columns
::: {.column width="50%"}
Let $\bar{X}_1$ and $\bar{X}_2$ be the means of random samples from two independent groups, with parameters shown in table:
:::

::: {.column width="50%"}
|             | Group 1    | Group 2    |
|-------------|------------|------------|
| sample size | $n_1$      | $n_2$      |
| pop mean    | $\mu_1$    | $\mu_2$    |
| pop sd      | $\sigma_1$ | $\sigma_2$ |
:::
:::

::: {style="font-size: 90%;"}
Some theoretical statistics:

* If $\bar{X}_1$ and $\bar{X}_2$ are independent normal r.v.'s, then $\bar{X}_1 - \bar{X}_2$ is also normal
* What is the mean of $\bar{X}_1 - \bar{X}_2$? 

$$E[\bar{X}_1 - \bar{X}_2] = E[\bar{X}_1] - E[\bar{X}_2] = \mu_1-\mu_2$$

* What is the standard deviation of $\bar{X}_1 - \bar{X}_2$?

\begin{align}
Var(\bar{X}_1 - \bar{X}_2) &= Var(\bar{X}_1) + Var(\bar{X}_2) = \frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2} \\
SD(\bar{X}_1 - \bar{X}_2) &= \sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}
\end{align}

:::


## Step 3: Test statistic (part 2)

::: {style="font-size: 90%;"}
::: columns
::: {.column width="50%"}
$$
t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

:::

::: {.column width="50%"}
* $\bar{x}_1, \bar{x}_2$ are the sample means
* $\mu_0=0$ is the mean value specified in $H_0$
* $s_1, s_2$ are the sample SD's
* $n_1, n_2$ are the sample sizes

:::
:::


* Statistical theory tells us that $t_{\bar{x}_1 - \bar{x}_2}$ follows a __student's t-distribution__ with 
    * $df \approx$ smaller of $n_1-1$ and $n_2-1$
    * this is a conservative estimate (smaller than actual $df$ )

__Assumptions__:

* __Independent observations & samples__
    * The observations were collected independently. 
    * In particular, the observations from the two groups were not paired in any meaningful way.
* __Approximately normal samples or big n's__ 
    * The distributions of the samples should be approximately normal 
    * _or_ _both_ their sample sizes should be at least 30.
:::



## Step 3: Test statistic (part 3)

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
CaffTaps %>% group_by(Group) %>% get_summary_stats(type = "mean_sd") %>% gt()
```

$$
\text{test statistic} = t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

:::
::: {.column width="60%"}

```{r}
#| include: false
# 1: caffeine
# 2: no caffeine
n1 <- 10
n2 <- 10
(xbar1 <- sumstats$mean[1])
(xbar2 <- sumstats$mean[2])
(diff_x <- xbar1 - xbar2)
(sd1 <- sumstats$sd[1])
(sd2 <- sumstats$sd[2])
mu <- 0

(se <- sqrt(sd1^2/n1 + sd2^2/n2))
(tstat <- (diff_x - mu)/se)

alpha <- 0.05
(p_area <- 1-alpha/2)

1-pt(tstat, df=min(n1 -1, n2-1))
pt(tstat, df=min(n1 -1, n2-1), lower.tail = FALSE)

2*(1-pt(tstat, df=min(n1 -1, n2-1)))
```

:::
:::

<br>

<br>

<hr>

Based on the value of the test statistic, do you think we are going to reject or fail to reject $H_0$?



## Step "3b": Assumptions satisfied?
::: columns
::: {.column width="50%"}
__Assumptions__:

* __Independent observations & samples__
    * The observations were collected independently. 
    * In particular, the observations from the two groups were not paired in any meaningful way.

* __Approximately normal samples or big n's__ 
    * The distributions of the samples should be approximately normal 
    * _or_ _both_ their sample sizes should be at least 30.

:::

::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
ggplot(CaffTaps, aes(x=Taps)) +
  geom_dotplot() +
  facet_wrap(vars(Group), ncol=1)
```
:::
:::


## Step 4: p-value

The __[p-value]{style="color:darkorange"}__ is the __probability__ of obtaining a test statistic _just as extreme or more extreme_ than the observed test statistic assuming the null hypothesis $H_0$ is true. 

::: columns
::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 4
#| echo: false
# specify upper and lower bounds of shaded region below
mu <- 0
std <- se

# The following figure is only an approximation of the 
# sampling distribution since I used a normal instead
# of t-distribution to make it.

ggplot(data.frame(x = c(mu-5*std, mu+5*std)), aes(x = x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = std)) + 
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks=c(mu, mu - 1*(1:5), mu + 1*(1:5))) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0)) +
  labs(y = "", 
       x = "difference in means",
       title = "Sampling distribution of difference in means") +
  geom_vline(xintercept = c(diff_x), 
             color = "red")
```

```{r}
#| fig.height: 3
#| fig.width: 10
#| echo: false
ggplot(data = data.frame(x = c(-5, 5)), aes(x)) + 
  stat_function(fun = dt, args = list(df = min(n1 -1, n2-1))) + 
  ylab("") + 
  xlab("t-dist with df = 9") +
  scale_y_continuous(breaks = NULL) + 
  scale_x_continuous(breaks=c(mu, mu - (1:5), mu + (1:5))) +
  geom_vline(xintercept = c(tstat), 
             color = "red")
```


:::

::: {.column width="50%"}

Calculate the _p_-value:

```{r}
#| include: false
# 1: caffeine
# 2: no caffeine
# n1 <- 10
# n2 <- 10
# (xbar1 <- sumstats$mean[1])
# (xbar2 <- sumstats$mean[2])
# (diff_x <- xbar1 - xbar2)
# (sd1 <- sumstats$sd[1])
# (sd2 <- sumstats$sd[2])
# mu <- 0
# 
# (se <- sqrt(sd1^2/n1 + sd2^2/n2))
# (tstat <- (diff_x - mu)/se)
# 
# alpha <- 0.05
# (p_area <- 1-alpha/2)

1-pt(tstat, df=min(n1 -1, n2-1))
pt(tstat, df=min(n1 -1, n2-1), lower.tail = FALSE)

2*(1-pt(tstat, df=min(n1 -1, n2-1)))
```

:::
:::



## Step 5: Conclusion to hypothesis test

\begin{align}
H_0:& \mu_{caff} - \mu_{ctrl} = 0\\
H_A:& \mu_{caff} - \mu_{ctrl} > 0\\
\end{align}

* Recall the $p$-value = 0.00397
* Use $\alpha$ = 0.05.
* Do we reject or fail to reject $H_0$?

__Conclusion statement__:

* Stats class conclusion
    * There is sufficient evidence that the (population) difference in mean finger taps/min with vs. without caffeine is greater than 0 ( $p$-value = 0.004).

* More realistic manuscript conclusion: 
    * The mean finger taps/min were 244.8 (SD = 2.4) and 248.3 (SD = 2.2) for the control and caffeine groups, and the increase of 3.5 taps/min was statistically discrenible ( $p$-value = 0.004).


## 95% CI for the mean difference in cholesterol levels

```{r}
#| echo: false
CaffTaps %>% group_by(Group) %>% get_summary_stats(type = "mean_sd") %>% gt()
```

```{r}
#| include: false
# 1: caffeine
# 2: no caffeine
# n1 <- 10
# n2 <- 10
# (xbar1 <- sumstats$mean[1])
# (xbar2 <- sumstats$mean[2])
# (diff_x <- xbar1 - xbar2)
# (sd1 <- sumstats$sd[1])
# (sd2 <- sumstats$sd[2])
# mu <- 0
# 
# (se <- sqrt(sd1^2/n1 + sd2^2/n2))
# (tstat <- (diff_x - mu)/se)
# 
# 1-pt(tstat, df=min(n1 -1, n2-1))
# pt(tstat, df=min(n1 -1, n2-1), lower.tail = FALSE)
# 
# 2*(1-pt(tstat, df=min(n1 -1, n2-1)))
alpha <- 0.05
(p_area <- 1-alpha/2)

(tstar <- qt(p_area, df=min(n1 -1, n2-1))) 
# (se <- sqrt(sd1^2/n1 + sd2^2/n2))
(moe <- tstar * se) 
(LB <- diff_x - moe)
(UB <- diff_x + moe)
```

::: columns
::: {.column width="50%"}
CI for $\mu_{caff} - \mu_{ctrl}$:

$$\bar{x}_{caff} - \bar{x}_{ctrl} \pm t^* \cdot \sqrt{\frac{s_{caff}^2}{n_{caff}}+\frac{s_{ctrl}^2}{n_{ctrl}}}$$

:::

::: {.column width="50%"}

:::
:::

<br>
<br>
<br>

::: {style="font-size: 90%;"}
__Interpretation__:  
We are 95% confident that the (population) difference in mean finger taps/min between the caffeine and control groups is between `r round(LB, 3)` mg/dL and `r round(UB, 3)` mg/dL.

* _Based on the CI, is there evidence that drinking caffeine made a difference in finger taps/min? Why or why not?_
:::



## R: 2-sample t-test (with long data)

* The `CaffTaps` data are in a *long* format, meaning that 
    * all of the outcome values are in one column and 
    * another column indicates which group the values are from
* This is a common format for data from multiple samples, especially if the sample sizes are different.

<!-- Using the caffeine induced finger tapping example with $H_A: \mu_{caff} - \mu_{ctrl} > 0$: -->

```{r}
(Taps_2ttest <- t.test(formula = Taps ~ Group, 
                       alternative = "greater", 
                       data = CaffTaps))
```

<!-- * The test output gives the 1-sided 95% CI since we ran a 1-sided test -->



## `tidy` the `t.test` output


```{r}
# use tidy command from broom package for briefer output that's a tibble
tidy(Taps_2ttest) %>% gt()
```

* Pull the p-value:

```{r}
tidy(Taps_2ttest)$p.value  # we can pull specific values from the tidy output
```


## R: 2-sample t-test (with wide data)

<!-- Using the caffeine induced finger tapping example with $H_A: \mu_{caff} - \mu_{ctrl} > 0$: -->

```{r}
# make CaffTaps data wide: pivot_wider needs an ID column so that it 
# knows how to "match" values from the Caffeine and NoCaffeine groups
CaffTaps_wide <- CaffTaps %>% 
  mutate(id = rep(1:10, 2)) %>% #  "fake" IDs for pivot_wider step
  pivot_wider(names_from = "Group",
              values_from = "Taps")

glimpse(CaffTaps_wide)

t.test(x = CaffTaps_wide$Caffeine, y = CaffTaps_wide$NoCaffeine, alternative = "greater") %>% 
  tidy() %>% gt()
```



## Why are the df's in the R output different?

From many slides ago:

* Statistical theory tells us that $t_{\bar{x}_1 - \bar{x}_2}$ follows a __student's t-distribution__ with 
    * $df \approx$ smaller of $n_1-1$ and $n_2-1$
    * this is a __conservative__ estimate (smaller than actual $df$ )

The actual degrees of freedom are calculated using  Satterthwaite's method:

$$\nu = \frac{[ (s_1^2/n_1) + (s_2^2/n_2) ]^2}
{(s_1^2/n_1)^2/(n_1 - 1) + (s_2^2/n_2)^2/(n_2-1) }
= \frac{ [ SE_1^2 + SE_2^2 ]^2}{ SE_1^4/df_1 + SE_2^4/df_2 }$$

<hr>

Verify the _p_-value in the R output using $\nu$ = 17.89012:

```{r}
pt(3.3942, df = 17.89012, lower.tail = FALSE)
``` 


## Pooled standard deviation estimate {.smaller}

* Sometimes we have reasons to believe that the population SD's from the two groups are equal, such as when randomizing participants to two groups

::: columns
::: {.column width="60%"}
* In this case we can use a __pooled SD__:

$$s_{pooled}^2 = \frac{s_1^2 (n_1-1) + s_2^2 (n_2-1)}{n_1 + n_2 - 2}$$
:::

::: {.column width="40%"}
* $n_1$, $n_2$ are the sample sizes, and
* $s_1$, $s_2$ are the sample standard deviations 
* of the two groups 
:::
:::

* We use the pooled SD instead of $s_1^2$ and $s_2^2$ when calculating the standard error 

$$SE = \sqrt{\frac{s_{pooled}^2}{n_1} + \frac{s_{pooled}^2}{n_2}}= s_{pooled}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$$

::: columns
::: {.column width="50%"}

__Test statistic__ with pooled SD:

$$t_{\bar{x}_1 - \bar{x}_2} = \frac{\bar{x}_1 - \bar{x}_2 -0}{s_{pooled}\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$

:::

::: {.column width="50%"}
__CI__  with pooled SD:

$$(\bar{x}_1 - \bar{x}_2) \pm t^{\star} \cdot s_{pooled} \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$$
:::
:::

* The $t$ distribution degrees of freedom are now:

$$df = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2.$$


```{r}
#| echo: false
#| eval: false
(sp <- (2.214^2 + 2.394^2)/2)
sqrt(sp)
```



## R: 2-sample t-test with pooled SD 

```{r}
# t-test with pooled SD
t.test(formula = Taps ~ Group, 
       alternative = "greater", 
       var.equal = TRUE,  # pooled SD 
       data = CaffTaps) %>% 
  tidy() %>% 
  gt()

# t-test without pooled SD
t.test(formula = Taps ~ Group, 
       alternative = "greater", 
       var.equal = FALSE,  # default, NOT pooled SD 
       data = CaffTaps) %>% 
  tidy() %>% 
  gt()
```

Similar output in this case - why??




## What's next? 

::: {style="font-size: 90%;"}
CI's and hypothesis tests for different scenarios:

$$\text{point estimate} \pm z^*(or~t^*)\cdot SE,~~\text{test stat} = \frac{\text{point estimate}-\text{null value}}{SE}$$

Day | Book | Population <br> parameter | Symbol | Point estimate | Symbol | SE
--|--|--|--|--|--|--
10 | 5.1 | Pop mean | $\mu$ | Sample mean | $\bar{x}$ | $\frac{s}{\sqrt{n}}$
10 | 5.2 | Pop mean of paired diff | $\mu_d$ or $\delta$ | Sample mean of paired diff | $\bar{x}_{d}$  | **$\frac{s_d}{\sqrt{n}}$**
11 | 5.3 | [Diff in pop <br> means]{style="color:green"} | [$\mu_1-\mu_2$]{style="color:green"} | [Diff in sample <br> means]{style="color:green"} | [$\bar{x}_1 - \bar{x}_2$]{style="color:green"}  | [**$\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}$ or pooled**]{style="color:red"}
12 | 8.1 | [Pop proportion]{style="color:darkblue"} | [$p$]{style="color:darkblue"} | [Sample prop]{style="color:darkblue"} | [$\widehat{p}$]{style="color:darkblue"}  | [**???**]{style="color:red"}
12 | 8.2 | [Diff in pop <br> proportions]{style="color:darkblue"} | [$p_1-p_2$]{style="color:darkblue"} | [Diff in sample <br> proportions]{style="color:darkblue"} | [$\widehat{p}_1-\widehat{p}_2$]{style="color:darkblue"} | [**???**]{style="color:red"}

:::