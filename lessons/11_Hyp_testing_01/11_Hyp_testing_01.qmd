---
title: "Lesson 11: Hypothesis Testing 1: Single-sample mean"
subtitle: "TB sections 4.3, 5.1"
author: "Meike Niederhausen and Nicky Wakim"
title-slide-attributes:
    data-background-color: "#3070BF"
date: "11/6/2024"
format: 
  revealjs:
    theme: "../simple_NW.scss"
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Lesson 11 Slides
    html-math-method: mathjax
    highlight-style: arrow
execute:
  echo: true
  freeze: auto
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) # NEW!!

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

set.seed(456)
```

## Where are we?

![](../img_slides/course_map.png){fig-align="center"}

## Where are we? Continuous outcome zoomed in {visibility="hidden"}

<br> <br>

![](../img_slides/flowchart_only_continuous.jpg){fig-align="center"}

# Learning Objectives

1.  Understand the relationship between point estimates, confidence intervals, and hypothesis tests.
2.  Determine if s single-sample mean is different than a population mean using a hypothesis test.
3.  Use R to calculate the test statistic, p-value, and confidence interval for a single-sample mean.

```{css, echo=FALSE}
.reveal code {
  max-height: 100% !important;
}
```

# Learning Objectives

::: lob
1.  Understand the relationship between point estimates, confidence intervals, and hypothesis tests.
:::

2.  Determine if s single-sample mean is different than a population mean using a hypothesis test.
3.  Use R to calculate the test statistic, p-value, and confidence interval for a single-sample mean.

## Answering a research question

**Research question is a generic form:** Is there evidence to support that the population mean is different than $\mu$?

 

Two approaches to answer this question:

:::::::::::: columns
:::::: {.column width="49%"}
::::: green2
::: green2-ttl
Confidence interval
:::

::: green2-cont
-   Create a **confidence interval (CI)** for the population mean $\mu$ from our sample data and determine whether a prescribed value is inside the CI or not.
-   Answering the question: is $\mu$ a plausible value given our data?
:::
:::::
::::::

::: {.column width="2%"}
:::

:::::: {.column width="49%"}
::::: pink
::: pink-ttl
Hypothesis test
:::

::: pink-cont
-   Run a **hypothesis test** to see if there is evidence that the population mean $\mu$ is *significantly different* from a prescribed value
-   This does not give us a range of plausible values for the population mean $\mu$.
-   Instead, we calculate a *test statistic* and *p-value*
-   See how likely we are to observe the sample mean $\overline{x}$ or a more extreme sample mean assuming that the population mean $\mu$ is a prescribed value
:::
:::::
::::::
::::::::::::

## Last last time: Point estimates

```{r}
#| echo: false
#| fig-width: 18
#| fig-height: 5
#| fig-align: center

set.seed(4258)
means=NULL;sds=NULL
for(i in 1:1000){
  height = rnorm(50, 65, 3)
  means = c(means, mean(height))
  sds = c(sds, sd(height))
}
means50 = as.data.frame(cbind(1:1000, means, sds))
mu <- 65
SE <- 3/sqrt(50)
sig <- round(SE, 2)

samp_dist50_plot2 = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47")
  

samp_dist50_plot2

```

![](../img_slides/sample_point_est.png){fig-align="center"}

## Last time: Point estimates with their confidence intervals for $\mu$

:::::: columns
::: {.column width="22%"}
 

![](../img_slides/samp_point_est_vert.png){fig-align="center"}
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-width: 9
#| fig-height: 10
#| fig-align: center

samp_dist_blue = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  annotate("rect", xmin = 64.7 - 1.95*.424, 
           xmax = 64.7 + 1.95*.424, 
           ymin = 0, ymax = 1.1,
           alpha = .3, fill = "#0070C0") +
  ylim(0, 1.1)

samp_dist_red = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  annotate("rect", xmin = 65.1 - 1.95*.424, 
           xmax = 65.1 + 1.95*.424, 
           ymin = 0, ymax = 1.1,
           alpha = .3, fill = "#C00000") +
  ylim(0, 1.1)

samp_dist_yell = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  annotate("rect", xmin = 64.9 - 1.95*.424, 
           xmax = 64.9 + 1.95*.424, 
           ymin = 0, ymax = 1.1,
           alpha = .3, fill = "#FFC000") +
  ylim(0, 1.1)

samp_dist_green = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  annotate("rect", xmin = 66.1 - 1.95*.424, 
           xmax = 66.1 + 1.95*.424, 
           ymin = 0, ymax = 1.1,
           alpha = .3, fill = "#70AD47") +
  ylim(0, 1.1)

library(patchwork)

samp_dist_blue / samp_dist_yell / samp_dist_red / samp_dist_green

```
:::

::: {.column width="28%"}
Do these confidence intervals include $\mu$?
:::
::::::

## This time: Point estimates with probability assuming population mean $\mu$

:::::: columns
::: {.column width="22%"}
 

![](../img_slides/samp_point_est_vert.png){fig-align="center"}
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-width: 9
#| fig-height: 10
#| fig-align: center

samp_dist_blue = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                xlim = c(63, 64.7), 
                geom = "area", fill = "#0070C0", 
                alpha = 0.6)+
  ylim(0, 1.1)

samp_dist_red = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                xlim = c(65.1, 67), 
                geom = "area", fill = "#C00000", 
                alpha = 0.6)+
  ylim(0, 1.1)

samp_dist_yell = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                xlim = c(63, 64.9), 
                geom = "area", fill = "#FFC000", 
                alpha = 0.6)+
  ylim(0, 1.1)

samp_dist_green = means50 %>% 
  ggplot(aes(x=means)) + 
  geom_histogram(color="black", fill="grey", bins=60, 
                 aes(y=..density..)) +
  labs(x="Mean height from samples (inches)", y="Density") +
  scale_x_continuous(breaks = seq(60, 70, by = 1), 
                     limits = c(63, 67)) +
  theme(text = element_text(size = 27), 
        axis.title = element_blank()) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                size = 3, 
                color = "#5BAFF8") +
  geom_vline(xintercept = 65.1, size = 3, color = "#C00000") +
  geom_vline(xintercept = 64.7, size = 3, color = "#0070C0") +
  geom_vline(xintercept = 64.9, size = 3, color = "#FFC000") +
  geom_vline(xintercept = 66.1, size = 3, color = "#70AD47") +
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = sig), 
                xlim = c(66.1, 67), 
                geom = "area", fill = "#70AD47", 
                alpha = 0.6)+
  ylim(0, 1.1)

library(patchwork)

samp_dist_blue / samp_dist_yell / samp_dist_red / samp_dist_green

```
:::

::: {.column width="28%"}
Assuming the population mean is $\mu$, what is the probability that we observe $\overline{x}$ or a more extreme sample mean?
:::
::::::

## Last time: Confidence interval (CI) for the mean $\mu$ ($z$ vs. $t$)

- In summary, we have two cases that lead to different ways to calculate the confidence interval

::::: columns
::: {.column width="50%"}
::: blue2
::: blue2-ttl
Case 1: We know the population standard deviation
:::
::: blue2-cont
$$\overline{x}\ \pm\ z^*\times \text{SE}$$

- with $\text{SE} = \frac{\sigma}{\sqrt{n}}$ and $\sigma$ is the population standard deviation

 

- For 95% CI, we use:
  - $z^* =$ `qnorm(p = 0.975)` $=1.96$
:::
:::
:::

::: {.column width="50%"}
::: red
::: red-ttl
Case 2: We **do not** know the population sd
:::
::: red-cont
$$\overline{x}\ \pm\ t^*\times \text{SE}$$

- with $\text{SE} = \frac{s}{\sqrt{n}}$ and $s$ is the sample standard deviation

 

- For 95% CI, we use:
  - $t^* =$ `qt(p = 0.975, df = n-1)`
:::
:::
:::
:::::

## Poll Everywhere Question 1



## This time: Hypothesis test ($z$ vs. $t$)

- We have two different distributions from which we run a hypothesis test

::::: columns
::: {.column width="50%"}
::: blue2
::: blue2-ttl
Case 1: We know the population standard deviation
:::
::: blue2-cont

- We use a test statistic from a Normal distribution: 
$$z_{\overline{x}} = \dfrac{\overline{x} - \mu}{SE}$$

- with $\text{SE} = \frac{\sigma}{\sqrt{n}}$ and $\sigma$ is the population standard deviation

:::
:::
:::

::: {.column width="50%"}
::: red
::: red-ttl
Case 2: We **do not** know the population sd
:::
::: red-cont
- We use a test statistic from a Student's t-distribution: 
$$t_{\overline{x}} = \dfrac{\overline{x} - \mu}{SE}$$

- with $\text{SE} = \frac{s}{\sqrt{n}}$ and $\sigma$ is the sample standard deviation

 

-   This is usually the case in real life

:::
:::
:::
:::::


## Is 98.6°F really the mean "healthy" body temperature?

-   [**We will illustrate how to perform a hypothesis test as we work through this example**]{style="color:#5BAFF8"}
-   **Where did the 98.6°F value come from?**
    -   German physician Carl Reinhold August [Wunderlich](https://www.google.com/books/edition/_/a6UNq33GPfIC?hl=en&gbpv=1&pg=PP14) determined 98.6°F (or 37°C) based on temperatures from 25,000 patients in Leipzig in 1851.
-   [1992 JAMA article](https://jamanetwork.com/journals/jama/article-abstract/400116) by Mackowiak, Wasserman, & Levine
    -   They claim that 98.2°F (36.8°C) is a more accurate average body temp
    -   Sample: n = 148 healthy individuals aged 18 - 40 years
-   Other research indicating that the human body temperature is lower
    -    [*Decreasing human body temperature in the United States since the Industrial Revolution*](https://elifesciences.org/articles/49555)
    -    [*Defining Usual Oral Temperature Ranges in Outpatients Using an Unsupervised Learning Algorithm*](https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2809098)
    -   NYT article [The Average Human Body Temperature Is Not 98.6 Degrees](../resources/NYT_What_Is_a_Fever_Why_Your_Body_Temperature_May_Be_Cooler_Than_98.6_Degrees.pdf)

::: lob
**Question:** based on the 1992 JAMA data, is there evidence to support that the population mean body temperature is different from 98.6°F?
:::

## Question: based on the 1992 JAMA data, is there evidence to support that the population mean body temperature is different from 98.6°F?

Two approaches to answer this question:

:::::::::::: columns
:::::: {.column width="49%"}
::::: green2
::: green2-ttl
Confidence interval
:::

::: green2-cont
-   Create a **confidence interval (CI)** for the population mean $\mu$ and determine whether 98.6°F is inside the CI or not.
-   Answering the question: is 98.6°F a plausible value?
:::
:::::
::::::

::: {.column width="2%"}
:::

:::::: {.column width="49%"}
::::: pink2
::: pink2-ttl
Hypothesis test
:::

::: pink2-cont
-   Run a **hypothesis test** to see if there is evidence that the population mean $\mu$ is *significantly different* from 98.6°F or not
-   This does not give us a range of plausible values for the population mean $\mu$.
-   Instead, we calculate a *test statistic* and *p-value*
-   See how likely we are to observe the sample mean $\overline{x}$ or a more extreme sample mean assuming that the population mean $\mu$ is 98.6°F
:::
:::::
::::::
::::::::::::

## [Approach 1: Create a 95% CI for the population mean body temperature]{style="color:#459B99"}

-   Use data based on the results from the 1992 JAMA study
    -   The original dataset used in the JAMA article is not available
    -   However, Allen Shoemaker from Calvin College created a [dataset](http://jse.amstat.org/datasets/normtemp.dat.txt) with the same summary statistics as in the JAMA article, which we will use:

$$\overline{x} = 98.25,~s=0.733,~n=130$$

```{r}
#| include: false
n <- 130
xbar <- 98.25
sd <- 0.733
(tstar <- qt(.975, df=n-1))  # df = n-1
(se <- sd/sqrt(n))
(moe <- tstar * se) 
(LB <- xbar - moe)
(UB <- xbar + moe)
```

::::: columns
::: {.column width="40%"}
CI for $\mu$: \begin{align}
\overline{x} &\pm t^*\cdot\frac{s}{\sqrt{n}}\\
98.25 &\pm `r round(tstar,3)`\cdot\frac{0.733}{\sqrt{130}}\\
98.25 &\pm `r round(moe,3)`\\
(`r round(LB, 3)`&, `r round(UB, 3)`)
\end{align}
:::

::: {.column width="60%"}
 

Used $t^*$ = `qt(.975, df=129)` = `r round(qt(.975, df=129),3)`

 

**Conclusion:** We are 95% confident that the (population) mean body temperature is between `r round(LB, 3)`°F and `r round(UB, 3)`°F, which is discernably different than 98.6°F.
:::
:::::

## [Approach 2: Hypothesis Test]{style="color:#BF396F"}

From before:

-   Run a **hypothesis test** to see if there is evidence that the population mean $\mu$ is *significantly different* from 98.6°F or not.
    -   This does not give us a range of plausible values for the population mean $\mu$.

    -   Instead, we calculate a *test statistic* and *p-value*

        -   to see how likely we are to observe the sample mean $\overline{x}$
        -   or a more extreme sample mean
        -   assuming that the population mean $\mu$ is 98.6°F.

**How do we calculate a *test statistic* and *p-value*?**

-   Use the sampling distribution and central limit theorem!!
-   Focus on Case 2: we don't know the population sd $\sigma$

# Learning Objectives

1.  Understand the relationship between point estimates, confidence intervals, and hypothesis tests.

::: lob
2.  Determine if s single-sample mean is different than a population mean using a hypothesis test.
:::

3.  Use R to calculate the test statistic, p-value, and confidence interval for a single-sample mean.

## Steps in a Hypothesis Test

1. Check the [**assumptions**]{style="color:#3070BF"}

2.  Set the [**level of significance**]{style="color:#3070BF"} $\alpha$

3.  Specify the [**null**]{style="color:#3070BF"} ( $H_0$ ) and [**alternative**]{style="color:#3070BF"} ( $H_A$ ) [**hypotheses**]{style="color:#3070BF"}

    1.  In symbols
    2.  In words
    3.  Alternative: one- or two-sided?

4.  Calculate the [**test statistic**]{style="color:#3070BF"}.

5.  Calculate the [**p-value**]{style="color:#3070BF"} based on the observed test statistic and its sampling distribution

6.  Write a [**conclusion**]{style="color:#3070BF"} to the hypothesis test

    1.  Do we reject or fail to reject $H_0$?
    2.  Write a conclusion in the context of the problem

## Step 1: Check the assumptions

- The assumptions to run a hypothesis test on a sample are:

    -   **Independent observations**: the observations were collected independently.
    -   **Approximately normal sample or big n**: the distribution of the sample should be approximately normal, *or* the sample size should be at least 30

 

- These are the criteria for the Central Limit Theorem in Lesson 09: Variability in estimates

 

- In our example, we would check the assumptions with a statement:

  - The individual observations are independent and the number of individuals in our sample is 130. Thus, we can use CLT to approximate the sampling distribution.

## Step 2: Set the level of significance $\alpha$

-   **Before doing a hypothesis test**, we set a cut-off for how small the $p$-value should be in order to reject $H_0$.
- It is important to specify how rare or unlikely an event must be in order to represent sufficient
evidence against the null hypothesis. 

-   We call this the [**significance level**]{style="color:#3070BF"}, denoted by the Greek symbol [alpha ( $\alpha$ )]{style="color:#3070BF"}

      - Typically choose $\alpha = 0.05$
      
- This is parallel to our confidence interval
  - $\alpha$ is the probability of rejecting the null hypothesis when it is true (it's a measure of potential error)
  - From repeated ($1-\alpha$)% confidence intervals, we will have about $\alpha$% intervals that do not cover $\mu$ even though they come from the distribution with mean $\mu$
  
## Step 3: Null & Alternative Hypotheses (1/2)

In statistics, a **hypothesis** is a statement about the value of an **unknown population parameter**.

A [**hypothesis test**]{style="color:#3070BF"} consists of a test between two competing hypotheses:

1.  a [**null**]{style="color:#3070BF"} hypothesis $H_0$ (pronounced “H-naught”) vs.
2.  an [**alternative**]{style="color:#3070BF"} hypothesis $H_A$ (also denoted $H_1$)

Example of hypotheses in words:

\begin{aligned}
H_0 &: \text{The population mean body temperature is 98.6°F}\\
\text{vs. } H_A &: \text{The population mean body temperature is not 98.6°F}
\end{aligned}

1.  $H_0$ is a claim that there is “no effect” or “no difference of interest.”
2.  $H_A$ is the claim a researcher wants to establish or find evidence to support. It is viewed as a “challenger” hypothesis to the null hypothesis $H_0$

## Step 3: Null & Alternative Hypotheses (2/2)

::: columns
::: column
::: blue
::: blue-ttl
Notation for hypotheses
:::
::: blue-cont
\begin{aligned}
H_0 &: \mu = \mu_0\\
\text{vs. } H_A&: \mu \neq, <, \textrm{or}, > \mu_0
\end{aligned}
:::
:::
:::
::: column
::: pink
::: pink-ttl
Hypotheses test for example
:::
::: pink-cont
\begin{aligned}
H_0 &: \mu = 98.6\\
\text{vs. } H_A&: \mu \neq 98.6
\end{aligned}
:::
:::
:::
:::
We call $\mu_0$ the *null value* (hypothesized population mean from $H_0$)

::::::::: columns
:::: {.column width="32%"}
$H_A: \mu \neq \mu_0$

-   not choosing a priori whether we believe the population mean is greater or less than the null value $\mu_0$
::::

:::: {.column width="2%"}
::::

:::: {.column width="32%"}
$H_A: \mu < \mu_0$

-   believe the population mean is **less** than the null value $\mu_0$
::::

:::: {.column width="2%"}
::::

:::: {.column width="32%"}
$H_A: \mu > \mu_0$

-   believe the population mean is **greater** than the null value $\mu_0$

::::
:::::::::

-   $H_A: \mu \neq \mu_0$ is the most common option, since it's the most conservative

## Poll Everywhere Question 2



## Step 4: [Test statistic]{style="color:#3070BF"} (& its distribution)

::::: columns
::: {.column width="50%"}
::: blue2
::: blue2-ttl
Case 1: We know the population standard deviation
:::
::: blue2-cont

- We use a test statistic from a Normal distribution: 
$$z_{\overline{x}} = \dfrac{\overline{x} - \mu}{SE}$$

- with $\text{SE} = \frac{\sigma}{\sqrt{n}}$ and $\sigma$ is the population standard deviation

- Statistical theory tells us that [$z_{\overline{x}}$]{style="color:#3070BF"} follows a [**Standard Normal distribution** $N(0,1)$]{style="color:#3070BF"}
:::
:::
:::

::: {.column width="50%"}
::: red
::: red-ttl
Case 2: We **do not** know the population sd
:::
::: red-cont
- We use test statistic from Student's t-distribution: 
$$t_{\overline{x}} = \dfrac{\overline{x} - \mu}{SE}$$

- with $\text{SE} = \frac{s}{\sqrt{n}}$ and $\sigma$ is the sample standard deviation

-   Statistical theory tells us that [$t_{\overline{x}}$]{style="color:#C83532"} follows a [**Student's t distribution** with degrees of freedom (df) = $n-1$]{style="color:#C83532"}
:::
:::
:::
:::::


$\overline{x}$ = sample mean, $\mu_0$ = hypothesized population mean from $H_0$,\
$\sigma$ = *population* standard deviation, $s$ = *sample* standard deviation,\
$n$ = sample size



## Step 4: Test statistic calculation

From our example: Recall that $\overline{x} = 98.25$, $s=0.733$, and $n=130$

The test statistic is:

$$t_{\overline{x}} = \frac{\overline{x} - \mu_0}{\frac{s}{\sqrt{n}}}
= \frac{98.25 - 98.6}{\frac{0.73}{\sqrt{130}}}
= -5.45$$

-   Statistical theory tells us that $t_{\overline{x}}$ follows a **Student's t-distribution** with $df = n-1 = 129$



```{r}
#| fig.height: 4
#| fig.width: 10
#| fig-align: center
#| echo: false
ggplot(data = data.frame(x = c(-6, 6)), aes(x)) + 
  stat_function(fun = dt, args = list(df = 129)) + 
  ylab("") + 
  xlab("t-dist with df = 129") +
  scale_y_continuous(breaks = NULL) + 
  geom_vline(xintercept = c(-5.45,5.45), 
             color = "red")
```


## Step 5: p-value

The [**p-value**]{style="color:#3070BF"} is the [**probability** of obtaining a test statistic *just as extreme or more extreme* than the observed test statistic assuming the null hypothesis $H_0$ is true.]{style="color:#3070BF"}

::::: columns
::: {.column width="50%"}

 

-   The $p$-value is a quantification of "surprise"
    -   Assuming $H_0$ is true, *how surprised are we with the observed results*?
    -   *Ex*: assuming that the true mean body temperature is 98.6°F, how surprised are we to get a sample mean of 98.25°F (or more extreme)?
  
 
    
-   If the $p$-value is "small," it means there's a small probability that we would get the observed statistic (or more extreme) when $H_0$ is true.
:::

::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 7
#| echo: false
# specify upper and lower bounds of shaded region below
mu <- 98.6
std <- se

ggplot(data.frame(x = c(mu-5*std, mu+5*std)), aes(x = x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu, sd = std)) + 
  # stat_function(fun = dnorm, 
  #               args = list(mean = mu, sd = std), 
  #         # specify the upper and lower bounds of the shaded region:
  #               xlim = c(mu-4*std, xbar),             
  #               geom = "area", fill = "darkblue") +
  # the breaks values below might need to be adjusted 
  # if there are too many values showing on the x-axis
  # scale_x_continuous(breaks=(mu-4*std):(mu+4*std)) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks=c(mu, mu - 0.06*(1:5), mu + 0.06*(1:5))) +
  theme(axis.text.x=element_text(angle = -30, hjust = 0, size=22)) +
  labs(y = "", 
       x = "Sample means",
       title = "Sampling distribution of mean body temperatures")
```
:::
:::::

## Step 5: p-value calculation

Calculate the *p*-value using the **Student's t-distribution** with $df = n-1 = 130-1=129$:

$$\text{p-value}=P(T \leq -5.45) + P(T \geq 5.45) = 2.410889 \times 10^{-07}$$

```{r}
# use pt() instead of pnorm()
# need to specify df
2*pt(-5.4548, df = 130-1, lower.tail = TRUE)
```

```{r}
#| fig.height: 4
#| fig.width: 10
#| fig-align: center
#| echo: false
ggplot(data = data.frame(x = c(-6, 6)), aes(x)) + 
  stat_function(fun = dt, args = list(df = 129)) + 
  ylab("") + 
  xlab("t-dist with df = 129") +
  scale_y_continuous(breaks = NULL) + 
  geom_vline(xintercept = c(-5.45,5.45), 
             color = "red")
```

## Step 6: Conclusion to hypothesis test

\begin{aligned}
H_0 &: \mu = \mu_0\\
\text{vs. } H_A&: \mu \neq \mu_0
\end{aligned}

-   Need to compare p-value to our selected $\alpha = 0.05$
-   Do we reject or fail to reject $H_0$? 

\

::: columns
::: column

::: pink2
::: pink2-ttl
If $\text{p-value} < \alpha$, reject the null hypothesis
:::
::: pink2-cont
- There is sufficient evidence that the (population) mean body temperature is discernibly different from $\mu_0$ ( $p$-value = ___)
- The average (insert measure) in the sample was $\overline{x}$ (95% CI ___, ___), which is discernibly different from $\mu_0$ ( $p$-value = ____).
:::
:::

:::
::: column

::: green2
::: green2-ttl
If $\text{p-value} \geq \alpha$, fail to reject the null hypothesis
:::
::: green2-cont
- There is insufficient evidence that the (population) mean body temperature is discernibly different from $\mu_0$ ( $p$-value = ___)
- The average (insert measure) in the sample was $\overline{x}$ (95% CI ___, ___), which is not discernibly different from $\mu_0$ ( $p$-value = ____).
:::
:::

:::
:::

## Step 6: Conclusion to hypothesis test

\begin{aligned}
H_0 &: \mu = 98.6\\
\text{vs. } H_A&: \mu \neq 98.6
\end{aligned}

-   Recall the $p$-value = $2.410889 \times 10^{-07}$
-   Need to compare back to our selected $\alpha = 0.05$

-   Do we reject or fail to reject $H_0$?

**Conclusion statement**:

-   Basic: ("stats class" conclusion)
    -   There is sufficient evidence that the (population) mean body temperature is discernibly different from 98.6°F ( $p$-value \< 0.001).
-   Better: ("manuscript style" conclusion)
    -   The average body temperature in the sample was 98.25°F (95% CI 98.12, 98.38°F), which is discernibly different from 98.6°F ( $p$-value \< 0.001).
    
## Poll Everywhere Question 3


# Learning Objectives

1.  Understand the relationship between point estimates, confidence intervals, and hypothesis tests.
2.  Determine if s single-sample mean is different than a population mean using a hypothesis test.

::: lob
3.  Use R to calculate the test statistic, p-value, and confidence interval for a single-sample mean.
:::

## Load the dataset

-   The data are in a csv file called `BodyTemperatures.csv`

```{r}
library(here)   # first install this package

BodyTemps <- read.csv(here::here("data", "BodyTemperatures.csv"))
#                     location: look in "data" folder
#                               for the file "BodyTemperatures.csv"

glimpse(BodyTemps)
```

## `t.test`: base R's function for testing one mean

-   Use the body temperature example with $H_A: \mu \neq 98.6$
-   We called the dataset `BodyTemps` when we loaded it

```{r}
(temps_ttest <- t.test(x = BodyTemps$Temperature,
       alternative = "two.sided", # default setting
       mu = 98.6))
```

Note that the test output also gives the 95% CI using the t-distribution.

## `tidy()` the `t.test` output

-   Use the `tidy()` function from the `broom` package for briefer output in table format that's stored as a `tibble`
-   Combined with the `gt()` function from the `gt` package, we get a nice table

```{r}
tidy(temps_ttest) %>% 
  gt() %>% 
  tab_options(table.font.size = 40) # use a different size in your HW
```

-   Since the `tidy()` output is a tibble, we can easily `pull()` specific values from it:

::::: columns
::: {.column width="50%"}
Using base R's `$`

```{r}
tidy(temps_ttest)$p.value  
```

:::
:::::

## What's next?

CI's and hypothesis testing for different scenarios:

| Lesson | Section | Population parameter | Symbol (pop) | Point estimate | Symbol (sample) |
|:----------:|:----------:|:----------:|:----------:|:----------:|:----------:|
| 11 | 5.1 | Pop mean | $\mu$ | Sample mean | $\overline{x}$ |
| 12 | 5.2 | Pop mean of paired diff | $\mu_d$ or $\delta$ | Sample mean of paired diff | $\overline{x}_{d}$ |
| 13 | 5.3 | Diff in pop means | $\mu_1-\mu_2$ | Diff in sample means | $\overline{x}_1 - \overline{x}_2$ |
| 15 | 8.1 | Pop proportion | $p$ | Sample prop | $\widehat{p}$ |
| 15 | 8.2 | Diff in pop prop's | $p_1-p_2$ | Diff in sample prop's | $\widehat{p}_1-\widehat{p}_2$ |

## Reference: what does it all look like together?

::: pink
::: pink-ttl
Example of hypothesis test based on the 1992 JAMA data
:::
::: pink-cont
Is there evidence to support that the population mean body temperature is different from 98.6°F?
:::
:::

::: columns
::: {.column width="50%"}
1.  **Assumptions:** The individual observations are independent and the number of individuals in our sample is 130. Thus, we can use CLT to approximate the sampling distribution.

4-5. 
:::
::: {.column width="25%"}
2.  Set $\alpha = 0.05$
:::

::: {.column width="25%"}

3.  **Hypothesis:**

    \begin{aligned}
    H_0 &: \mu = 98.6\\
    \text{vs. } H_A&: \mu \neq 98.6
    \end{aligned}
:::
:::

```{r}
temps_ttest <- t.test(x = BodyTemps$Temperature, mu = 98.6)
tidy(temps_ttest) %>% gt() %>% tab_options(table.font.size = 36)
```

6.  **Conclusion:** We reject the null hypothesis. The average body temperature in the sample was 98.25°F (95% CI 98.12, 98.38°F), which is discernibly different from 98.6°F ( $p$-value \< 0.001).


