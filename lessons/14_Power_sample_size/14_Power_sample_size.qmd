---
title: "Lesson 14: Power and sample size calculations for means"
subtitle: "TB sections 5.4"
author: "Meike Niederhausen and Nicky Wakim"
title-slide-attributes:
    data-background-color: "#3070BF"
date: "11/20/2024"
format: 
  revealjs:
    theme: "../simple_NW.scss"
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Lesson 14 Slides
    html-math-method: mathjax
    highlight-style: arrow
execute:
  echo: true
  freeze: auto
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) # new-ish
library(here) # new-ish
library(pwr) # NEW!!

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

set.seed(456)
```

# Learning Objectives

1.  Understand the four components in equilibrium in a hypothesis test.
2.  Define the significance level, critical value, and rejection region.
3.  Define power and understand its role in a hypothesis test.
4.  Understand how to calculate power for two independent samples.
5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.

## Where are we?

![](../img_slides/course_map.png){fig-align="center"}

## Before we get into power and sample size

Let's watch this youtube video to jog our memory (remind us of what we learned):

{{< video https://www.youtube.com/watch?v=Q_pO9NzWxPY&ab_channel=DATAtab width="1400" height="850">}}

# Learning Objectives

::: lob
1.  Understand the four components in equilibrium in a hypothesis test.
:::

2.  Define the significance level, critical value, and rejection region.
3.  Define power and understand its role in a hypothesis test.
4.  Understand how to calculate power for two independent samples.
5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.

## From Lesson 13: Does caffeine increase finger taps/min (on average)?

-   [**Use this example to illustrate how to calculate a confidence interval and perform a hypothesis test for two independent samples**]{style="color:#5BAFF8"}

**Study Design**:[^1]

[^1]: Based on following article with extra simulations by me: Hand, David J.; Daly, Fergus; McConway, K.; Lunn, D. and Ostrowski, E. (1993). [A handbook of small data sets](https://www.crcpress.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780412399206). London, U.K.: Chapman and Hall.

-   70 college students students were trained to tap their fingers at a rapid rate
-   Each then drank 2 cups of coffee (double-blind)
    -   **Control** group: decaf
    -   **Caffeine** group: \~ 200 mg caffeine
-   After 2 hours, students were tested.
-   **Taps/minute** recorded

```{r}
#| fig.width: 10
#| fig.height: 6
#| include: false


CaffTaps <- read.csv(here::here("data", "CaffeineTaps_n35.csv"))

sumstats <- CaffTaps %>% 
  group_by(Group) %>% 
  get_summary_stats(type = "mean_sd") 
n1 <- 35
n2 <- 35
(xbar1 <- sumstats$mean[1])
(xbar2 <- sumstats$mean[2])
(diff_x <- xbar1 - xbar2)
(sd1 <- sumstats$sd[1])
(sd2 <- sumstats$sd[2])
mu <- 0

(se <- sqrt(sd1^2/n1 + sd2^2/n2))
```

## We started looking at the taps/min for each group

```{r}
#| fig.width: 10
#| fig.height: 8
#| code-fold: true
#| code-summary: Code to make these histograms
#| fig-align: center

ggplot(CaffTaps, aes(x=Taps)) +
  geom_histogram() +
  facet_wrap(vars(Group), ncol=1) +
  labs(y = "Number of people", x = "Taps/minute") +
  theme(text = element_text(size = 30))
```

## What if the following were the true population distributions? Case 1

-   Difference in population means is **5**
-   Both have a standard deviation of 2

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 250
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 254, y = 0.1, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

-   When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
    -   **Depends on the number of samples we get: we might need a lot**

## What if the following were the true population distributions? Case 2

-   Difference in population means is **5**
-   Both have a standard deviation of 1

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 250
mu2 = 245
sd = 1
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 242, y = 0.3, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 253, y = 0.3, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

-   When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
    -   **Seems easier to distinguish here.** How did the standard deviation decrease?

## What if the following were the true population distributions? Case 3

-   Difference in population means is **10**
-   Both have a standard deviation of 2

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 255
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 263)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 260, y = 0.1, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

-   When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
    -   **Also seems easier to distinguish here**

## There are a few things at play here

-   There are several measurements that affect how easy it is to distinguish between two populations
-   "Distinguish between two populations" = correctly reject the null hypothesis that they are the same

 

-   What elements are at play?

    1.  **Difference** in population means
    2.  **Number of samples** from each population
    3.  The **significance level** that we use for a cut off
    4.  The **power** of our test

-   More familiar with first two, but let's define #3 and #4 more

# Learning Objectives

1.  Understand the four components in equilibrium in a hypothesis test.

::: lob
2.  Define the significance level, critical value, and rejection region.
:::

3.  Define power and understand its role in a hypothesis test.
4.  Understand how to calculate power for two independent samples.
5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.

## Significance levels and critical values

::::::: {style="font-size: 90%;"}
-   **Critical values** are the cutoff values that determine whether a test statistic is statistically significant or not
    -   Determined by the **significance level**
-   If a test statistic is greater in absolute value than the critical value, we reject $H_0$

 

:::::: columns
::: {.column width="49%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.8, xlim = c(-3, -cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.6, xlim = c(-cv99, -cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.4, xlim = c(-cv95, -cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.1, xlim = c(-cv90, cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.4, xlim = c(cv90, cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.6, xlim = c(cv95, cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.8, xlim = c(cv99, 3)) +
  labs(x = "z", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-cv99, -cv95, -cv90, 0, cv90, cv95, cv99)) +
  theme(axis.text.x=element_text(angle = -35, hjust = 0)) +
  annotate("text", x = -2.8, y = .1, label = "0.005", size = 6) +
  annotate("text", x = -2.2, y = .1, label = "0.025", size = 6)  +
  annotate("text", x = -1.7, y = .1, label = "0.05", size = 6)  +
  annotate("text", x = 2.8, y = .1, label = "0.005", size = 6)  +
  annotate("text", x = 2.2, y = .1, label = "0.025", size = 6)  +
  annotate("text", x = 1.7, y = .1, label = "0.05", size = 6)  +
  labs(title="Critical Values for a Normal Distribution") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        text = element_text(size=24))
```
:::

::: {.column width="2%"}
:::

::: {.column width="49%"}
-   Critical values are determined by
    -   the significance level $\alpha$,
    -   whether a test is 1- or 2-sided, &
    -   the probability distribution being used to calculate the p-value (such as normal or t-distribution)
:::
::::::

-   We have been referring to critical values from the t-distribution as $t^*$
    -   See how we calculate a specific confidence interval in Lesson 10
:::::::

## Poll Everywhere Question 1

## Rejection region, significance levels, and critical values

-   If the absolute value of the test statistic is greater than the critical value, we reject $H_0$
    -   In this case the test statistic is in the **rejection region**.
    -   Otherwise it's in the non-rejection region.

::::: columns
::: {.column width="50%"}
![[Stats & Geospatial Analysis](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html)](../img_slides/RejectionRegion.png){fig-align="center"}
:::

::: {.column width="50%"}
-   What do rejection regions look like for 1-sided tests?
:::
:::::

# Learning Objectives

1.  Understand the four components in equilibrium in a hypothesis test.
2.  Define the significance level, critical value, and rejection region.

::: lob
3.  Define power and understand its role in a hypothesis test.
:::

4.  Understand how to calculate power for two independent samples.
5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.

## Let's start with some important definitions in words

-   **Type I error** ($\alpha$): Probability of rejecting the null hypothesis given that the null is true
-   **Type II error** ($\beta$): Probability of failing to reject the null hypothesis given that the null hypothesis is false
-   **Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)
-   **Specificity** ($1-\alpha$): Probability of failing to reject the null hypothesis given that the null is true (correct)

 

![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align="center"}

## What does that look like with our two populations?

:::::::: columns
::: {.column width="45%"}
![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align="center"}

-   [$\alpha$]{style="color:violet"} = probability of making a [**Type I error**]{style="color:violet"}
    -   This is the significance level (usually 0.05)
    -   Set before study starts
-   [$\beta$]{style="color:darkorange"} = probability of making a [**Type II error**]{style="color:darkorange"}
-   Ideally we want
    -   small Type I & II errors and
    -   big power
:::

::: {.column width="5%"}
:::

::::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.57

mu1 = 250
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 7, color = "#EF85B3") +
  annotate("text", x = 255, y = 0.1, label = "Caffeine", size = 7, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 20), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min") +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "violet", alpha =0.9, xlim = c(mu2 - 3*sd, mu2 -1.96*sd)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "skyblue", alpha =0.4, xlim = c(mu2 -1.96*sd, mu2 + 1.96*sd)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "violet", alpha =0.9, xlim = c(mu2 + 1.96* sd, 256)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean = mu1, sd = sd),fill = "sienna1", alpha =0.7, xlim = c(238, mu2 + 1.96*sd)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu1, sd = sd),fill = "green3", alpha =0.3, xlim = c(mu2 + 1.96*sd, 256)) +
    stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 2, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 2, 
                color = "#EF85B3") +
    annotate("text", x = 237.5, y = .01, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 249, y = .01, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 250, y = .1, label = "Power", hjust=0, size=6) +
  annotate("text", x = 245.3, y = .01, label = "P(Type II error)", hjust=0, size=6) 
two_sample_plot
```

:::: {style="font-size: 90%;"}
::: lob
**Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)
:::

-   Power is the correct region that is usually **in line with our study design**: studies are often seeing if there is a distinction between two populations
::::
:::::
::::::::

## Power

::::: columns
::: column
-   **Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)

 

-   Power is also called the
    -   true positive rate,
    -   probability of detection, or
    -   the *sensitivity* of a test

 

-   Typically, we aim for 80% or 90% power
:::

::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
two_sample_plot
```
:::
:::::

## Let's demonstrate the relationship between error and power

From the applet at <https://rpsychologist.com/d3/NHST/>

Let's look at the following scenarios:

::::: columns
::: column
1.  Solve for power: decreasing type 1 error ($\alpha$)

2.  Solve for power: increasing type 1 error ($\alpha$)

 

3.  Solve for power: decrease sample size

4.  Solve for power: increase sample size

 

5.  Solve for power: increase difference of means

6.  Solve for power: decrease difference of means
:::

::: column
 

-   Takeaway: cannot minimize both type 1 and 2 error

 

 

-   Takeaway: increasing sample size increases power

 

 

-   Takeaway: increasing difference in means increases power
:::
:::::

## If you want to keep revisiting these concepts!

From the applet at <https://rpsychologist.com/d3/NHST/>

::::: columns
::: {.column width="50%"}
![](../img_slides/power_applet_screenshot_alpha05.png){fig-align="center"}
:::

::: {.column width="50%"}
![](../img_slides/power_applet_screenshot_alpha01.png){fig-align="center"}
:::
:::::

-   Cohen's d is just a stanardized value to represent the difference in means: $$d = \dfrac{\overline{x}_1 - \overline{x}_2}{s}$$

# Learning Objectives

1.  Understand the four components in equilibrium in a hypothesis test.
2.  Define the significance level, critical value, and rejection region.
3.  Define power and understand its role in a hypothesis test.

::: lob
4.  Understand how to calculate power for two independent samples.
:::

5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.

## Calculating power or sample size

-   Typically, before we set up a research study, we try to find the needed sample size to achieve 80% or 90% power

 

-   If we have already have data, then we typically calculate the power based on the sample we have

## Example calculating power (1/3)

Let's say we have:

-   a null population with a normal distribution, centered at 0 with a standard deviation of 1 ($X_0 \sim Norm(0,1)$)
-   an alternative population, centered at 3 with a standard deviation of 1 ($X_A \sim Norm(3,1)$)

Find the power of a 2-sided test if the actual mean is $3$ and our significance level is 0.05.

## Example calculating power (2/3)

Let's say we have:

-   a null population with a normal distribution, centered at 0 with a standard error of 1 ($X_0 \sim Norm(0,1)$)
-   an alternative population, centered at 3 with a standard error of 1 ($X_A \sim Norm(3,1)$)

Find the power of a 2-sided test if the actual mean is $3$ and our significance level is 0.05.

::::: columns
::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  labs(x = "", y = "", title="Type I & II errors and power") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=6) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=6) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=6) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=6) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```
:::

::: {.column width="50%"}
-   Power = $P$ (Reject $H_0$ when alternative pop is true)
    -   Correctly reject null
-   When $\alpha$ = 0.05, we reject $H_0$ when the test statistic z is at least 1.96 (critical value is 1.96 under the null distribution)
-   Then we need to calculate the probability that we are in the rejection regions given we are **actually in the alternative population**
-   Thus under the alternative population, we need to calculate $P(X_A \le -1.96) + P(X_A \ge 1.96)$
:::
:::::

## Example calculating power (3/3)

::::: columns
::: {.column width="50%"}
```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  theme(axis.title = element_blank()) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=6) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=6) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=6) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=6) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```
:::

::: {.column width="50%"}
-   Thus under the alternative population, we need to calculate $P(X_A \le -1.96) + P(X_A \ge 1.96)$

-   Under the alternative population we have $X_A \sim Norm(3,1)$

```{r}
# left tail + right tail:
pnorm(-1.96, mean=3, sd=1, 
      lower.tail=TRUE) + 
  pnorm(1.96, mean=3, sd=1, 
        lower.tail=FALSE)
```

Answer: The power is 85%
:::
:::::

 

-   The left tail probability `pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE)` is essentially 0 in this case.
-   Note that this power calculation specified the value of the SE instead of the standard deviation and sample size $n$ individually.

# Learning Objectives

1.  Understand the four components in equilibrium in a hypothesis test.
2.  Define the significance level, critical value, and rejection region.
3.  Define power and understand its role in a hypothesis test.
4.  Understand how to calculate power for two independent samples.

::: lob
5.  Using R, calculate power and sample size for a single mean t-test and two independent mean t-test.
:::

## R package `pwr` for power analyses[^2]

[^2]: R package `pwr` for basic statistical tests: <https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html>

-   Use `pwr.t.test` for both one- and two-sample t-tests
-   Specify all parameters *except for* the one being solved for

```{r}
#| eval: false

pwr.t.test(n = NULL, 
           d = NULL, 
           sig.level = 0.05, 
           power = NULL,
           type = c("two.sample", "one.sample", "paired"),
           alternative = c("two.sided", "less", "greater"))
```

-   Leave out:

    -   `n`: returns sample size
    -   `d`: returns Cohen's d/effect size (next slide)
    -   `sig.level`: get significance level (not typical)
    -   `power`: returns power

## What is Cohen's $d$?

-   `d` is **Cohen's d** effect size
    -   Just a standardized way to measure the distance between the null mean and the alternative mean
-   Examples of values: small = 0.2, medium = 0.5, large = 0.8

::::::: columns
::: {.column width="33%"}
One-sample test (or paired t-test):
:::

::: {.column width="2%"}
:::

::: {.column width="20%"}
$$d = \frac{\mu-\mu_0}{s}$$
:::

::: {.column width="45%"}
:::
:::::::

::::::: columns
::: {.column width="33%"}
Two-sample test (independent):
:::

::: {.column width="2%"}
:::

::: {.column width="20%"}
$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$
:::

::: {.column width="45%"}
:::
:::::::

-   $\overline{x}_1 - \overline{x}_2$ is the difference in means between the two groups that one would want to be able to detect as being significant,
-   $s_{pooled}$ is the pooled SD between the two groups - often assume have same sd in each group

## **Power** calculation for testing one mean

::: {style="font-size: 90%;"}
Conversely, we can calculate how much power we had in our body temperature one-sample test, given the sample size of 130.

-   [**Calculate power**]{style="color:green"},
    -   given $\alpha$, $n$, "true" alternative mean $\mu$, and null $\mu_0$,
    -   *assuming* the test statistic is normal (instead of t-distribution)

$$1-\beta=
        P\left(Z \leq z-z_{1-\alpha/2}\right)+P\left(Z \leq -z-z_{1-\alpha/2}\right)
        \quad ,\quad \text{where } z=\frac{\mu-\mu_0}{s/\sqrt{n}}$$

$\Phi$ is the probability for a standard normal distribution

```{r}
mu <- 98.25; mu0 <- 98.6; sd <- 0.73; alpha <- 0.05; n <- 130
(z <- (mu-mu0) / (sd/sqrt(n)) )

(Power <- pnorm(z-qnorm(1-alpha/2)) + pnorm(-z-qnorm(1-alpha/2)))
```

If the population mean is 98.2 instead of 98.6, we have a 99.98% chance of correctly rejecting $H_0$ when the sample size is 130.
:::

## **Sample size** calculation for testing one mean

-   Recall in our body temperature example that $\mu_0=98.6$ °F and $\overline{x}= 98.25$ °F.
    -   The *p*-value from the hypothesis test was highly significant (very small).
    -   What would the sample size $n$ need to be for 80% power?
-   **Calculate** $n$
    -   given $\alpha$, power ( $1-\beta$ ), "true" alternative mean $\mu$, and null $\mu_0$
    -   Calculate `d`: $d = \frac{\mu-\mu_0}{s}$

## `pwr`: **sample size** for one mean test

Specify all parameters *except for* the sample size:

::::: columns
::: {.column width="40%"}
```{r}
library(pwr)
t.n <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "one.sample")

t.n
```
:::

::: {.column width="60%"}
```{r}
#| fig.width: 8
#| fig.height: 5
plot(t.n)
```

We **need 37 individuals** to detect this difference with 80% power.
:::
:::::

## `pwr`: **power** for one mean test

Specify all parameters *except for* the power:

::::: columns
::: {.column width="40%"}
```{r}
t.power <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  # power = 0.80, 
  n = 130,
  type = "one.sample")

t.power
```
:::

::: {.column width="60%"}
```{r}
#| fig.width: 10
#| fig.height: 6
plot(t.power)
```

We have **99.97% power** to detect this difference with 130 individuals.
:::
:::::

## `pwr`: Two-sample t-test: **sample size**

**Example**: Let's revisit our caffeine taps study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both group samples is 2.6.

Specify all parameters *except for* the sample size:

::::: columns
::: {.column width="45%"}
```{r}
t2.n <- pwr.t.test(
  d = 2/2.6, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "two.sample") 

t2.n
```
:::

::: {.column width="55%"}
```{r}
#| fig.width: 10
#| fig.height: 5
plot(t2.n)
```

We **need 28 individuals** to detect this difference with 80% power.
:::
:::::

::::::

## `pwr`: Two-sample t-test: **power**

**Example**: Let's revisit our caffeine taps study. Investigators want to know what power they have to detect a 2 point difference between the two groups. The two groups are both size 35 (like in our previous example). Assume the SD in both group samples is 2.6.

Specify all parameters *except for* the power:

::::: columns
::: {.column width="45%"}
```{r}
t2.power <- pwr.t.test(
  d = 2/2.3, 
  sig.level = 0.05, 
  n = 35,
  type = "two.sample") 

t2.power
```
:::

::: {.column width="55%"}
```{r}
#| fig.width: 10
#| fig.height: 5
plot(t2.power)
```

We have **94.8% power** to detect this difference with 35 individuals in each group.
:::
:::::

# Resources for power and sample size calculations

## More software for power and sample size calculations: PASS

-   PASS is a very powerful (& expensive) software that does power and sample size calculations for many advanced statistical modeling techniques.
    -   Even if you don't have access to PASS, their [documentation](https://www.ncss.com/software/pass/pass-documentation/) is very good and free online.
    -   Documentation includes formulas and references.
    -   PASS documentation for powering [means](https://www.ncss.com/software/pass/pass-documentation/#Means)
        -   One mean, paired means, two independent means
-   One-sample t-test documentation: <https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/One-Sample_T-Tests.pdf>

## OCTRI-BERD power & sample size presentations

::: {style="font-size: 90%;"}
-   **Power and Sample Size 101**
    -   Presented by Meike Niederhausen; April 13, 2023
    -   Slides: <http://bit.ly/PSS101-BERD-April2023>
    -   [Recording](https://echo360.org/media/10f37fa6-7196-4525-bd64-6b9fcca60ac0/public)
-   **Power and Sample Size for Clinical Trials: An Introduction**
    -   Presented by Yiyi Chen; Feb 18, 2021
    -   Slides: http://bit.ly/PSS-ClinicalTrials
    -   [Recording](https://echo360.org/lesson/9a21deb8-258d-4305-bdc9-7effdc35e719/classroom)
-   **Planning a Study with Power and Sample Size Considerations in Mind**
    -   Presented by David Yanez; May 29, 2019
    -   [Slides](https://www.ohsu.edu/sites/default/files/2019-12/PowerAndSampleSize_29MAY2019.pdf)
    -   [Recording](https://echo360.org/lesson/44c9a3e9-b8ec-4042-84d8-4758cc779a1f/classroom)
-   **Power and Sample Size Simulations in R**
    -   Presented by Robin Baudier; Sept 21, 2023
    -   [Slides](https://www.slideshare.net/ssuser84c78e/octri-pss-simulations-in-r-seminarpdf)
    -   [Recording](https://echo360.org/media/12e6e603-13f9-4b50-bf76-787185acdfce/public)
:::
