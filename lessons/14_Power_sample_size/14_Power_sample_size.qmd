---
title: "Lesson 14: Power and sample size calculations for difference of means"
subtitle: "TB sections 5.4"
author: "Meike Niederhausen and Nicky Wakim"
title-slide-attributes:
    data-background-color: "#3070BF"
date: "11/13/2024"
format: 
  revealjs:
    theme: "../simple_NW.scss"
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Lesson 14 Slides
    html-math-method: mathjax
    highlight-style: arrow
execute:
  echo: true
  freeze: auto
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) # new-ish
library(here) # new-ish
library(pwr) # NEW!!

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

set.seed(456)
```


# Learning Objectives

1. Understand the 4 components in equilibrium in a hypothesis test
2. Define the significance level, critical value, and rejection region.
3. Define power.
4. Calculate power 
5. Calculate the sample size
## Where are we?

![](../img_slides/course_map.png){fig-align="center"}

## From Lesson 13: Does caffeine increase finger taps/min (on average)?

-   [**Use this example to illustrate how to calculate a confidence interval and perform a hypothesis test for two independent samples**]{style="color:#5BAFF8"}

**Study Design**:[^1]

[^1]: Based on following article with extra simulations by me: Hand, David J.; Daly, Fergus; McConway, K.; Lunn, D. and Ostrowski, E. (1993). [A handbook of small data sets](https://www.crcpress.com/A-Handbook-of-Small-Data-Sets/Hand-Daly-McConway-Lunn-Ostrowski/p/book/9780412399206). London, U.K.: Chapman and Hall.

-   70 college students students were trained to tap their fingers at a rapid rate
-   Each then drank 2 cups of coffee (double-blind)
    -   **Control** group: decaf
    -   **Caffeine** group: \~ 200 mg caffeine
-   After 2 hours, students were tested.
-   **Taps/minute** recorded

```{r}
#| fig.width: 10
#| fig.height: 6
#| include: false


CaffTaps <- read.csv(here::here("data", "CaffeineTaps_n35.csv"))

sumstats <- CaffTaps %>% 
  group_by(Group) %>% 
  get_summary_stats(type = "mean_sd") 
n1 <- 35
n2 <- 35
(xbar1 <- sumstats$mean[1])
(xbar2 <- sumstats$mean[2])
(diff_x <- xbar1 - xbar2)
(sd1 <- sumstats$sd[1])
(sd2 <- sumstats$sd[2])
mu <- 0

(se <- sqrt(sd1^2/n1 + sd2^2/n2))
```

## We started looking at the taps/min for each group

```{r}
#| fig.width: 10
#| fig.height: 8
#| code-fold: true
#| code-summary: Code to make these histograms
#| fig-align: center

ggplot(CaffTaps, aes(x=Taps)) +
  geom_histogram() +
  facet_wrap(vars(Group), ncol=1) +
  labs(y = "Number of people", x = "Taps/minute") +
  theme(text = element_text(size = 30))
```

## What if the following were the true population distributions? Case 1

- Difference in population means is **5**
- Both have a standard deviation of 2


```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 250
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 254, y = 0.1, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
  - **Depends on the number of samples we get: we might need a lot**

## What if the following were the true population distributions? Case 2

- Difference in population means is **5**
- Both have a standard deviation of 1


```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 250
mu2 = 245
sd = 1
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 242, y = 0.3, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 253, y = 0.3, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
  - **Seems easier to distinguish here.** How did the standard deviation decrease?

## What if the following were the true population distributions? Case 3

- Difference in population means is **10**
- Both have a standard deviation of 2


```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 3
#| fig-align: center
#| warning: false
#| message: false

mu1 = 255
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 263)), aes(x)) + 
  stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 1.5, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 1.5, 
                color = "#EF85B3") +
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 5, color = "#EF85B3") +
  annotate("text", x = 260, y = 0.1, label = "Caffeine", size = 5, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 15), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min")
two_sample_plot
```

- When we take two samples from these groups, do you think it would be easy to distinguish between the mean taps/min?
  - **Also seems easier to distinguish here**

  
## There are a few things at play here

- There are several measurements that affect how easy it is to distinguish between two populations 
- "Distinguish between two populations" = reject the null hypothesis that they are the same

 

- What do we need?

    1. **Difference** in population means
    2. **Number of samples** from each population
    3. The **significance level** that we use for a cut off
    4. The **power** of our test
    
- More familiar with first two, but let's define #3 and #4 more

# Learning Objectives

## Significance levels and critical values 

::: {style="font-size: 90%;"}

* __Critical values__ are the cutoff values that determine whether a test statistic is statistically significant or not
    - Determined by the **significance level**
* If a test statistic is greater in absolute value than the critical value, we reject $H_0$

 

::: columns
::: {.column width="49%"}

```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.8, xlim = c(-3, -cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.6, xlim = c(-cv99, -cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.4, xlim = c(-cv95, -cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.1, xlim = c(-cv90, cv90)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.4, xlim = c(cv90, cv95)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.6, xlim = c(cv95, cv99)) +
  geom_area(stat = "function", fun = dnorm, fill = "#EF85B3", alpha =0.8, xlim = c(cv99, 3)) +
  labs(x = "z", y = "") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-cv99, -cv95, -cv90, 0, cv90, cv95, cv99)) +
  theme(axis.text.x=element_text(angle = -35, hjust = 0)) +
  annotate("text", x = -2.8, y = .1, label = "0.005", size = 6) +
  annotate("text", x = -2.2, y = .1, label = "0.025", size = 6)  +
  annotate("text", x = -1.7, y = .1, label = "0.05", size = 6)  +
  annotate("text", x = 2.8, y = .1, label = "0.005", size = 6)  +
  annotate("text", x = 2.2, y = .1, label = "0.025", size = 6)  +
  annotate("text", x = 1.7, y = .1, label = "0.05", size = 6)  +
  labs(title="Critical Values for a Normal Distribution") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        text = element_text(size=24))
```
:::

::: {.column width="2%"}
:::

::: {.column width="49%"}

* Critical values are determined by 
    * the significance level $\alpha$, 
    * whether a test is 1- or 2-sided, &
    * the probability distribution being used to calculate the p-value (such as normal or t-distribution)

:::
:::

* We have been referring to critical values from the t-distribution as $t^*$
    - See how we calculate a specific confidence interval
:::

## Poll Everywhere Question 1


## Significance levels and critical values and rejection region

* If the absolute value of the test statistic is greater than the critical value, we reject $H_0$
    * In this case the test statistic is in the __rejection region__.
    * Otherwise it's in the nonrejection region.

::: columns
::: {.column width="60%"}

![[Stats & Geospatial Analysis](https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html)](../img_slides/RejectionRegion.png){fig-align="center"}

:::
::: {.column width="40%"}

* What do rejection regions look like for 1-sided tests?

:::
:::


# LOB

## Let's start with some important definitions in words

- **Type I error** ($\alpha$): Probability of rejecting the null hypothesis given that the null is true
- **Type II error** ($\beta$): Probability of failing to reject the null hypothesis given that the null hypothesis is false
- **Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)
- **Specificity** ($1-\alpha$): Probability of failing to reject the null hypothesis given that the null is true (correct)

 

![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align="center"}



## What does that look like with our two populations?

::: columns
::: {.column width="45%"}

![](../img_slides/type-i-and-type-ii-errors_chart.png){fig-align="center"}


* [$\alpha$]{style="color:violet"} = probability of making a [__Type I error__]{style="color:violet"}
    * This is the significance level (usually 0.05)
    * Set before study starts
* [$\beta$]{style="color:#5DCA3B"} = probability of making a [__Type II error__]{style="color:#5DCA3B"}
* Ideally we want
    * small Type I & II errors and
    * big power

:::

::: {.column width="5%"}
:::

::: {.column width="50%"}

```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.57

mu1 = 250
mu2 = 245
sd = 2
diff_mu = mu1-mu2

two_sample_plot = ggplot(data.frame(x = c(238, 257)), aes(x)) + 
  annotate("text", x = 240, y = 0.1, label = "No Caffeine", size = 7, color = "#EF85B3") +
  annotate("text", x = 255, y = 0.1, label = "Caffeine", size = 7, color = "#5BAFF8") +
  theme_classic() +
  theme(text = element_text(size = 20), 
        axis.ticks.y = element_blank(), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank()) +
  labs(x = "Taps/min") +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "violet", alpha =0.9, xlim = c(mu2 - 3*sd, mu2 -1.96*sd)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "skyblue", alpha =0.4, xlim = c(mu2 -1.96*sd, mu2 + 1.96*sd)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu2, sd = sd),fill = "violet", alpha =0.9, xlim = c(mu2 + 1.96* sd, 256)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean = mu1, sd = sd),fill = "sienna1", alpha =0.7, xlim = c(238, mu2 + 1.96*sd)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean = mu1, sd = sd),fill = "green3", alpha =0.3, xlim = c(mu2 + 1.96*sd, 256)) +
    stat_function(fun = dnorm, 
                args = list(mean = mu1, sd = sd), 
                size = 2, 
                color = "#5BAFF8") +
  stat_function(fun = dnorm, 
                args = list(mean = mu2, sd = sd), 
                size = 2, 
                color = "#EF85B3") +
    annotate("text", x = 237.5, y = .01, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 249, y = .01, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 250, y = .1, label = "Power", hjust=0, size=6) +
  annotate("text", x = 245.3, y = .01, label = "P(Type II error)", hjust=0, size=6) 
two_sample_plot
```

::: {style="font-size: 90%;"}

::: lob
**Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)
:::

- Power is the correct region that is usually **in line with our study design**: studies are often seeing if there is a distinction between two populations

:::

:::
:::

## Power

::: columns
::: column
- **Power** (or sensitivity) ($1 - \beta$): Probability of rejecting the null hypothesis given that the null is false (correct)

 

* Power is also called the
    * true positive rate,
    * probability of detection, or 
    * the _sensitivity_ of a test

 

- Typically, we aim for 80% or 90% power
:::

::: {.column width="50%"}

```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
two_sample_plot
```
:::
:::

## If you want to keep revisiting these concepts!
        
From the applet at <https://rpsychologist.com/d3/NHST/>

::: columns
::: {.column width="50%"}

![](../img_slides/power_applet_screenshot_alpha05.png){fig-align="center"}

:::

::: {.column width="50%"}

![](../img_slides/power_applet_screenshot_alpha01.png){fig-align="center"}
:::
:::

- Cohen's d is just a stanardized value to represent the difference in means: $$d = \dfrac{\overline{x}_1 - \overline{x}_2}{s}$$

# LOB

## Example calculating power

* Suppose the mean of the null population is 0 ( $H_0: \mu=0$ ) with standard error 1
* Find the power of a 2-sided test if the actual $\mu=3$, assuming the SE doesn't change.


::: columns
::: {.column width="50%"}

```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  labs(x = "", y = "", title="Type I & II errors and power") +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=6) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=6) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=6) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=6) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```
:::

::: {.column width="50%"}
* Power = $P$ (Reject $H_0$ when alternative pop is true)
  - Correctly reject null
* When $\alpha$ = 0.05, we reject $H_0$ when the test statistic z is at least 1.96
* We need to look at the rejection region under the null, then calculate the probability that we are in those regions given we are actually in the alternative population
* Thus for $X\sim N(3,1)$ we need to calculate $P(X \le -1.96) + P(X \ge 1.96)$
:::
:::

## Example calculating power: using `pnorm()`

::: columns
::: {.column width="50%"}

```{r}
#| fig.width: 10
#| fig.height: 6
#| echo: false
cv90 <- 1.645
cv95 <- 1.96
cv99 <- 2.575

ggplot(NULL, aes(c(-3,7))) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(-3, -1.96)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "skyblue", alpha =0.4, xlim = c(-1.96, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=0,sd=1),fill = "violet", alpha =0.9, xlim = c(1.96,4)) +
    geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "sienna1", alpha =0.7, xlim = c(-1, 1.96)) +
  geom_area(stat = "function", fun = dnorm, args = list(mean=3,sd=1),fill = "green3", alpha =0.3, xlim = c(1.96, 6)) +
  theme(axis.title = element_blank()) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2, 3, 4)) +
  annotate("text", x = -3, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 2, y = .015, label = "P(Type I error)/2", hjust=0, size=6) +
  annotate("text", x = 3, y = .15, label = "Power", hjust=0, size=6) +
  annotate("text", x = .4, y = .05, label = "P(Type II error)", hjust=0, size=6) +
  annotate("text", x = -1, y = .3, label = "Null Population", hjust=0, size=6) +
  annotate("text", x = 2, y = .3, label = "Alternative Population", hjust=0, size=6) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```
:::

::: {.column width="50%"}

* Thus for $X\sim N(3,1)$ we need to calculate $P(X \le -1.96) + P(X \ge 1.96)$:

```{r}
# left tail + right tail:
pnorm(-1.96, mean=3, sd=1, 
      lower.tail=TRUE) + 
  pnorm(1.96, mean=3, sd=1, 
        lower.tail=FALSE)
```

:::

:::

 

- The left tail probability `pnorm(-1.96, mean=3, sd=1, lower.tail=TRUE)` is essentially 0 in this case.
- Note that this power calculation specified the value of the SE instead of the standard deviation and sample size $n$ individually.

# LOB

## __Sample size__ calculation for testing one mean

::: {style="font-size: 90%;"}

* Recall in our body temperature example that $\mu_0=98.6$ °F and $\bar{x}= 98.25$ °F. 
    * The _p_-value from the hypothesis test was highly significant (very small).
    * What would the sample size $n$ need to be for 80% power?

* [__Calculate $n$__]{style="color:green"}, 
    * given $\alpha$, power ( $1-\beta$ ), "true" alternative mean $\mu$, and null $\mu_0$, 
    * _assuming_ the test statistic is normal (instead of t-distribution):

::: columns
::: {.column width="30%"}

$$n=\left(s\frac{z_{1-\alpha/2}+z_{1-\beta}}{\mu-\mu_0}\right)^2$$
:::

::: {.column width="70%"}
```{r}
mu <- 98.25
mu0 <- 98.6
sd <- 0.73
alpha <- 0.05
beta <- 0.20
(n <- (sd*(qnorm(1-alpha/2) + qnorm(1-beta)) / (mu-mu0))^2)
ceiling(n)  # always round UP to the next highest integer 
```
:::
:::

_We would only need a sample size of 35 for 80% power!_  
However, this is an under-estimate since we used the normal instead of t-distribution.
:::

::: {style="font-size: 70%;"}
See <http://powerandsamplesize.com/Calculators/Test-1-Mean/1-Sample-Equality>.
:::


## __Power__ calculation for testing one mean

::: {style="font-size: 90%;"}
Conversely, we can calculate how much power we had in our body temperature one-sample test, given the sample size of 130.

* [__Calculate power__]{style="color:green"}, 
    * given $\alpha$, $n$, "true" alternative mean $\mu$, and null $\mu_0$, 
    * _assuming_ the test statistic is normal (instead of t-distribution)

$$1-\beta=
		P\left(Z \leq z-z_{1-\alpha/2}\right)+P\left(Z \leq -z-z_{1-\alpha/2}\right)
		\quad ,\quad \text{where } z=\frac{\mu-\mu_0}{s/\sqrt{n}}$$

$\Phi$ is the probability for a standard normal distribution 

```{r}
mu <- 98.25; mu0 <- 98.6; sd <- 0.73; alpha <- 0.05; n <- 130
(z <- (mu-mu0) / (sd/sqrt(n)) )

(Power <- pnorm(z-qnorm(1-alpha/2)) + pnorm(-z-qnorm(1-alpha/2)))
```

If the population mean is 98.2 instead of 98.6, we have a 99.98% chance of correctly rejecting $H_0$ when the sample size is 130.  

:::


## R package `pwr` for power analyses

::: {style="font-size: 90%;"}

* Use `pwr.t.test` for both one- and two-sample t-tests.  
* Specify all parameters _except for_ the one being solved for.

`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),`  
`alternative = c("two.sided", "less", "greater"))`

`d` is __Cohen's d__ effect size: small = 0.2, medium = 0.5, large = 0.8

::: columns
::: {.column width="49%"}
One-sample test (or paired t-test):
:::
::: {.column width="2%"}
:::
::: {.column width="49%"}

$$d = \frac{\mu-\mu_0}{s}$$ 

:::
:::

::: columns
::: {.column width="49%"}
Two-sample test (independent):
:::
::: {.column width="2%"}
:::
::: {.column width="49%"}

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$

:::
:::

:::

::: {style="font-size: 80%;"}
* $\bar{x}_1 - \bar{x}_2$ is the difference in means between the two groups that one would want to be able to detect as being significant,
* $s_{pooled}$ is the pooled SD between the two groups - often assume have same sd in each group


* R package `pwr` for basic statistical tests
    * <https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html>
:::


## `pwr`: __sample size__ for one mean test 

::: {style="font-size: 80%;"}
`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`
:::

* `d` is __Cohen's d__ effect size: $d = \frac{\mu-\mu_0}{s}$ 

Specify all parameters _except for_ the sample size:

::: columns
::: {.column width="40%"}

```{r}
library(pwr)
t.n <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "one.sample")

t.n
```

:::

::: {.column width="60%"}
```{r}
#| fig.width: 8
#| fig.height: 5
plot(t.n)
```
:::
:::


## `pwr`: __power__ for one mean test 

::: {style="font-size: 80%;"}
`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`
:::

* `d` is __Cohen's d__ effect size: $d = \frac{\mu-\mu_0}{s}$ 

Specify all parameters _except for_ the power:

::: columns
::: {.column width="40%"}

```{r}
t.power <- pwr.t.test(
  d = (98.6-98.25)/0.73, 
  sig.level = 0.05, 
  # power = 0.80, 
  n = 130,
  type = "one.sample")

t.power
```

:::

::: {.column width="60%"}
```{r}
#| fig.width: 10
#| fig.height: 6
plot(t.power)
```
:::
:::
 

## `pwr`: Two-sample t-test: __sample size__

::: {style="font-size: 70%;"}
`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`
:::

::: {style="font-size: 85%;"}

* `d` is __Cohen's d__ effect size: $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$

__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. 

Specify all parameters _except for_ the sample size:
:::

::: {style="font-size: 90%;"}

::: columns
::: {.column width="40%"}

```{r}
t2.n <- pwr.t.test(
  d = 2/2.3, 
  sig.level = 0.05, 
  power = 0.80, 
  type = "two.sample") 

t2.n
```

:::

::: {.column width="60%"}
```{r}
#| fig.width: 10
#| fig.height: 5
plot(t2.n)
```
:::
:::

:::

## `pwr`: Two-sample t-test: __power__

::: {style="font-size: 70%;"}
`pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,`   
`type = c("two.sample", "one.sample", "paired"),` 
`alternative = c("two.sided", "less", "greater"))`
:::

::: {style="font-size: 85%;"}

* `d` is __Cohen's d__ effect size: $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$

__Example__: Suppose the data collected for the caffeine taps study were pilot day for a larger study. Investigators want to know what sample size they would need to detect a 2 point difference between the two groups. Assume the SD in both groups is 2.3. 

Specify all parameters _except for_ the power:
:::

::: {style="font-size: 90%;"}

::: columns
::: {.column width="40%"}

```{r}
t2.power <- pwr.t.test(
  d = 2/2.3, 
  sig.level = 0.05, 
  # power = 0.80, 
  n = 22,
  type = "two.sample") 

t2.power
```

:::

::: {.column width="60%"}
```{r}
#| fig.width: 10
#| fig.height: 5
plot(t2.power)
```
:::
:::

:::

## What information do we need for a power (or sample size) calculation?

::: columns
::: {.column width="40%"}
There are 4 pieces of information:

1. Level of significance $\alpha$
    * Usually fixed to 0.05
1. Power
    * Ideally at least 0.80
1. Sample size
1. Effect size (expected change)

Given any 3 pieces of information, we can solve for the 4th.
:::

::: {.column width="60%"}
```{r}
pwr.t.test(
  d = (98.6-98.25)/0.73,
  sig.level = 0.05, 
  # power = 0.80, 
  n=130,
  type = "one.sample")
```
:::
:::


## More software for power and sample size calculations: PASS 

* PASS is a very powerful (& expensive) software that does power and sample size calculations for many advanced statistical modeling techniques.
    * Even if you don't have access to PASS, their [documentation](https://www.ncss.com/software/pass/pass-documentation/) is very good and free online.
    * Documentation includes formulas and references.
    * PASS documentation for powering [means](https://www.ncss.com/software/pass/pass-documentation/#Means)
        * One mean, paired means, two independent means

* One-sample t-test documentation:
<https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/One-Sample_T-Tests.pdf>


## OCTRI-BERD power & sample size presentations

::: {style="font-size: 90%;"}

* __Power and Sample Size 101__
  * Presented by Meike Niederhausen; April 13, 2023
  * Slides: <http://bit.ly/PSS101-BERD-April2023>
  * [Recording](https://echo360.org/media/10f37fa6-7196-4525-bd64-6b9fcca60ac0/public)

* __Power and Sample Size for Clinical Trials: An Introduction__
  * Presented by Yiyi Chen; Feb 18, 2021
  * Slides: http://bit.ly/PSS-ClinicalTrials
  * [Recording](https://echo360.org/lesson/9a21deb8-258d-4305-bdc9-7effdc35e719/classroom)

* __Planning a Study with Power and Sample Size Considerations in Mind__
  * Presented by David Yanez; May 29, 2019
  * [Slides](https://www.ohsu.edu/sites/default/files/2019-12/PowerAndSampleSize_29MAY2019.pdf)
  * [Recording](https://echo360.org/lesson/44c9a3e9-b8ec-4042-84d8-4758cc779a1f/classroom)

* __Power and Sample Size Simulations in R__
  * Presented by Robin Baudier; Sept 21, 2023
  * [Slides](https://www.slideshare.net/ssuser84c78e/octri-pss-simulations-in-r-seminarpdf)
  * [Recording](https://echo360.org/media/12e6e603-13f9-4b50-bf76-787185acdfce/public)

:::
