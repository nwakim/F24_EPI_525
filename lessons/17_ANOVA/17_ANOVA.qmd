---
title: "Lesson 17: Comparing Means with ANOVA"
subtitle: "TB sections 5.5"
author: "Meike Niederhausen and Nicky Wakim"
title-slide-attributes:
    data-background-color: "#3070BF"
date: "12/2/2024"
format: 
  revealjs:
    theme: "../simple_NW.scss"
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Lesson 17 Slides
    html-math-method: mathjax
    highlight-style: arrow
execute:
  echo: true
  freeze: auto
---

```{r}
#| label: "setup" 
#| include: false
#| message: false
#| warning: false

library(tidyverse)    
library(oibiostat)
library(janitor)
library(rstatix)
library(knitr)
library(gtsummary)
library(moderndive)
library(gt)
library(broom) 
library(here) 
library(pwr) 

data("famuss")

# terminal: for icons
# quarto install extension quarto-ext/fontawesome

# set ggplot theme for slides 
theme_set(theme_bw(base_size = 22))
# theme_update(text = element_text(size=16))  # set global text size for ggplots

```

# Learning Objectives

1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).

2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.

3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. 

4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.

```{css, echo=FALSE}
.reveal code {
  max-height: 100% !important;
}
.reveal pre.sourceCode code {
  max-height: 100% !important;
}
```

## Where are we?

![](../img_slides/course_map.png){fig-align="center"}


## A little while ago...

-   We looked at inference for a **single mean**
-   We looked at inference for a difference in **means from two independent samples**

 

-   If there are two groups, we could see if they had different means by testing if the difference between the means were the same (null) or different (alternative)

 

-   What happens when we want to compare two **or more** groups' means?

    -   Can no longer rely on the difference in means
    -   Need a new method to make inference (ANOVA or Linear Regression!)

# Learning Objectives

::: lob
1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).
:::

2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.

3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. 

4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.

## From Lesson 8: Data visualization

- Study investigating whether ACTN3 genotype at a particular location (residue 577) is associated with change in muscle function

 

- **Categorical variable:** genotypes (CC, TT, CT)

 

- **Numeric variable:** Muscle function, measured as percent change in non-dominant arm strength

 

- We can start the investigation by plotting the relationship

## From Lesson 8: Side-by-side boxplots with data points

- We can look at the boxplot of percent change for each genotype **with points shown so we can see the distribution of observations better**

::: columns
::: {.column width="53%"}
```{r}
#| label: "box_sbs_jitter"
#| eval: false
#| code-line-numbers: "7-11"
ggplot(data = famuss, 
       aes(x = actn3.r577x, 
           y = ndrm.ch)) + 
  geom_boxplot() + 
  labs(x = "ACTN3 genotype", 
       y = "Percent Change in Non-Dominant Arm Strength")  +
  geom_jitter(aes(color = actn3.r577x), 
    alpha = 0.3,      
    show.legend = FALSE,      
    position = position_jitter(     
      height = 0.4))      
```

:::
::: {.column width="47%"}
```{r}
#| label: "box_sbs_jitter_out"
#| ref.label: "box_sbs_jitter"
#| echo: false
#| fig.keep: "first"
#| fig.height: 7.5
#| fig.width: 7
```
:::
:::

## From Lesson 8: Ridgeline plot 

- Overlapped densities were easy enough to see with 3 genotypes
- If you have **many categories**, a ridgeline plot might make it easier to see

::: columns
::: {.column width="53%"}
```{r}
#| label: "density_ridge"
#| eval: false
#| code-line-numbers: "6-7"
library(ggridges)
ggplot(data = famuss, 
       aes(y = actn3.r577x, 
           x = ndrm.ch, 
           fill = actn3.r577x)) +
  geom_density_ridges(alpha = 0.3, 
          show.legend = FALSE) +      
  labs(x = "Percent Change in Non-Dominant Arm Strength",
       y = "ACTN3 genotype",
       title = "Strength change by genotype")       
```
:::
::: {.column width="47%"}
```{r}
#| label: "density_ridge_out"
#| ref.label: "density_ridge"
#| echo: false
#| fig.keep: "first"
#| fig.height: 7.5
#| fig.width: 7.5
```
:::
:::

## Poll Everywhere Question 1


# Learning Objectives

1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).

::: lob
2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.
:::

3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. 

4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.

## Comparing means

::: columns
::: {.column width="40%"}
Whether or not two means are significantly different depends on:

* How far apart the __means__ are
* How much __variability__ there is within each group

__[Questions:]{style="color:#C83532"}__  

* How to measure variability __between__ groups?
* How to measure variability __within__ groups?
* How to compare the two measures of variability?
* How to determine significance?
:::

::: {.column width="60%"}
![](../img_slides/toyANOVA.png)
:::
:::

## Generic ANOVA table

![](../img_slides/anova_table.png){fig-align="center" height=7in}

## ANOVA: Analysis of Variance  {.nostretch}

__ANOVA__ compares the variability between groups to the variability within groups 


![](../img_slides/anova_total_variability.png){fig-align="center" height=1.75in}

::: columns
::: {.column width=33%}
```{r}
#| fig.width: 7
#| fig.height: 8
#| echo: false

var_tot_plot = ggplot(famuss, aes(x = actn3.r577x, y=ndrm.ch, 
      fill = actn3.r577x, color = actn3.r577x)) +
  # geom_dotplot(binaxis = "y", alpha =.9) +
  geom_jitter(aes(color = actn3.r577x), 
    alpha = 0.7, size = 4,      
    show.legend = FALSE,      
    position = position_jitter(     
      height = 0.4)) +  
  geom_hline(aes(yintercept = mean(ndrm.ch)), 
             lty = "dashed", size = 2) +
  # stat_summary(fun = "mean", geom = "point", 
  #      size = 3, color = "grey33", alpha =1)  +
  theme(legend.position = "none") +
  labs(y = "Percent Change in Non-Dominant Arm Strength",
       x = "ACTN3 genotype") + ylim(-1, 175)
var_tot_plot
```
:::

::: {.column width=33%}
```{r}
#| fig.width: 7
#| fig.height: 8
#| echo: false
var_bw_gp_plot = ggplot(famuss, aes(x = actn3.r577x, y=ndrm.ch, 
      fill = actn3.r577x, color = actn3.r577x)) +
  geom_jitter(aes(color = actn3.r577x), 
    alpha = 0.2, size = 4,      
    show.legend = FALSE,      
    position = position_jitter(     
      height = 0.4)) +  
  geom_hline(aes(yintercept = mean(ndrm.ch)), 
             lty = "dashed", size = 2) +
  stat_summary(fun = "mean", geom = "point", 
       size = 5, color = "grey33", alpha =1)  +
  theme(legend.position = "none") +
  labs(y = "Percent Change in Non-Dominant Arm Strength",
       x = "ACTN3 genotype") + ylim(-1, 175)
var_bw_gp_plot
```
:::

::: {.column width=33%}
```{r}
#| fig.width: 7
#| fig.height: 8
#| echo: false
var_win_gp_plot = ggplot(famuss, aes(x = actn3.r577x, y=ndrm.ch, 
      fill = actn3.r577x, color = actn3.r577x)) +
  geom_jitter(aes(color = actn3.r577x), 
    alpha = 0.5, size = 4,      
    show.legend = FALSE,      
    position = position_jitter(     
      height = 0.4)) +    # geom_hline(aes(yintercept = mean(ndrm.ch)), 
  #            lty = "dashed", size = 2)
  stat_summary(fun = "mean", geom = "point", 
       size = 5, color = "grey33", alpha =1)  +
  theme(legend.position = "none") +
  labs(y = "Percent Change in Non-Dominant Arm Strength",
       x = "ACTN3 genotype") + ylim(-1, 175)
var_win_gp_plot
```
:::
:::

## ANOVA: Analysis of Variance  {.nostretch}

__Analysis of Variance (ANOVA)__ compares the variability between groups to the variability within groups 

![](../img_slides/anova_total_variability.png){fig-align="center" height=2in}


$$\sum_{i = 1}^k \sum_{j = 1}^{n_i}(x_{ij} -\bar{x})^2 \ \ 
= \ \sum_{i = 1}^k n_i(\bar{x}_{i}-\bar{x})^2 \ \ 
+ \ \ \sum_{i = 1}^k\sum_{j = 1}^{n_i}(x_{ij}-\bar{x}_{i})^2$$


![](../img_slides/anova_SS_total.png){fig-align="center" height=2in}




## Notation

::: columns
::: {.column width="30%"}

* _k_ groups
* $n_i$ observations in each of the _k_ groups
* Total sample size is $N=\sum_{i=1}^{k}n_i$
* $\bar{x}_{i}$ = mean of observations in group _i_
* $\bar{x}$ = mean of _all_ observations
* $s_{i}$ = sd of observations in group _i_
* $s$ = sd of _all_ observations

:::

::: {.column width="70%"}

| Observation | *i* = 1       | *i* = 2       | *i* = 3       | $\ldots$ | *i* = *k*     | overall   |
|:------------|:-------------:|:-------------:|:-------------:|:--------:|:-------------:|:---------:|
| *j* = 1     | $x_{11}$      | $x_{21}$      | $x_{31}$      | $\ldots$ | $x_{k1}$      |           |
| *j* = 2     | $x_{12}$      | $x_{22}$      | $x_{32}$      | $\ldots$ | $x_{k2}$      |           |
| *j* = 3     | $x_{13}$      | $x_{23}$      | $x_{33}$      | $\ldots$ | $x_{k3}$      |           |
| *j* = 4     | $x_{14}$      | $x_{24}$      | $x_{34}$      | $\ldots$ | $x_{k4}$      |           |
| $\vdots$    | $\vdots$      | $\vdots$      | $\vdots$      | $\ddots$ | $\vdots$      |           |
| *j* = $n_i$ | $x_{1n_1}$      | $x_{2n_2}$      | $x_{3n_3}$      | $\ldots$ | $x_{kn_k}$      |           |
| Means       | $\bar{x}_{1}$ | $\bar{x}_{2}$ | $\bar{x}_{3}$ | $\ldots$ | $\bar{x}_{k}$ | $\bar{x}$ |
| Variance    | ${s}^2_{1}$   | ${s}^2_{2}$   | ${s}^2_{3}$   | $\ldots$ | ${s}^2_{k}$   | ${s}^2$   |

:::
:::




## Total Sums of Squares (SST)

::: columns
::: {.column width="40%"}
```{r}
#| fig.width: 7
#| fig.height: 10
#| echo: false
var_tot_plot
```

:::
::: {.column width="60%"}

Total Sums of Squares:

$$SST = \sum_{i = 1}^k \sum_{j = 1}^{n_i}(x_{ij} -\bar{x})^2 = (N-1)s^2$$

* where 
    * $N=\sum_{i=1}^{k}n_i$ is the total sample size and
    * $s^2$ is the grand standard deviation of all the observations

* This is the sum of the squared differences between each observed $x_{ij}$ value and the *grand mean*, $\bar{x}$. 

* That is, it is the total deviation of the $x_{ij}$'s from the grand mean. 

:::
:::

## Sums of Squares due to Groups (SSG)

::: columns
::: {.column width="40%"}
```{r}
#| fig.width: 7
#| fig.height: 10
#| echo: false
var_bw_gp_plot
```
:::
::: {.column width="60%"}
Sums of Squares due to Groups:

$$SSG = \sum_{i = 1}^k n_i(\bar{x}_{i}-\bar{x})^2$$

* This is the sum of the squared differences between each *group* mean, $\bar{x}_{i}$, and the *grand mean*, $\bar{x}$. 

* That is, it is the deviation of the group means from the grand mean.

* Also called the Model SS, or $SS_{model}.$

:::
:::

## Sums of Squares Error (SSE)

::: columns
::: {.column width="40%"}
```{r}
#| fig.width: 7
#| fig.height: 10
#| echo: false
var_win_gp_plot

```
:::
::: {.column width="60%"}
Sums of Squares Error:

$$SSE = \sum_{i = 1}^k\sum_{j = 1}^{n_i}(x_{ij}-\bar{x}_{i})^2 = \sum_{i = 1}^k(n_i-1)s_{i}^2$$
where $s_{i}$ is the standard deviation of the $i^{th}$ group

* This is the sum of the squared differences between each observed $x_{ij}$ value and its group mean $\bar{x}_{i}$. 

* That is, it is the deviation of the $x_{ij}$'s from the predicted ndrm.ch by group.

* Also called the residual sums of squares, or $SS_{residual}.$

:::
:::

## Poll Everywhere Question 2

## ANOVA table to hypothesis test?

- Okay, so how do we use all these types of variability to run a test? 
- How do we determine, statistically, if the groups have different means or not?

![](../img_slides/anova_table.png){fig-align="center"}

- Answer: We use the F-statistic in a hypothesis test!

# Learning Objectives

1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).

2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.

::: lob
3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. 
:::

4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.

## Thinking about the F-statistic

::: columns
::: {.column width="49.5%"}
__[If the groups are actually different, then which of these is more accurate?]{style="color:#C83532"}__

1. **The variability between groups should be higher than the variability within groups**
1. The variability within groups should be higher than the variability between groups

:::

::: {.column width="1%"}
:::

::: {.column width="49.5%"}
__[If there really is a difference between the groups, we would expect the F-statistic to be which of these: ]{style="color:#C83532"}__

1. **Higher than we would observe by random chance**
1. Lower than we would observe by random chance

:::
:::

![](../img_slides/hypothetical_disability_data_v2.png){fig-align="center"}


## The F-statistic

- F-statistic represents the standardized ratio of variability between groups to the variability within the groups

$$F_{stat} = \dfrac{MSG}{MSE}$$

- F is larger when the variability between groups is larger than variability within groups


## The F-distribution

::: columns
::: {.column width="45%"}

* The F-distribution is skewed right
* The F-distribution has __[two different degrees of freedom]{style="color:#BF396F"}__:
    * one for the [numerator]{style="color:#BF396F"} of the ratio [(k – 1)]{style="color:#BF396F"} and 
    * one for the [denominator (N – k)]{style="color:#BF396F"}

* [$p$-__value__]{style="color:#459B99"}  
    * $P(F > F_{stat})$
    * is always the __[upper tail]{style="color:#459B99"}__
    * (the area as extreme or more extreme)
:::

::: {.column width="55%"}

```{r}
#| fig.width: 10
#| fig.height: 8
#| echo: false
F_stat <- 2.6
ggplot(data.frame(x = c(0, 6)), aes(x = x)) + # set x-axis bounds from 0 to 6
  # fun = df is specifying (d)ensity of (f) distribution
  stat_function(fun = df, args = list(df1=4, df2=65), color = "#BF396F", size=3) +
  geom_vline(xintercept = F_stat, color = "#3070BF", size = 2) +
  geom_area(stat = "function", fun = df, args = list(df1=4, df2=65), fill = "#459B99", alpha =0.3, xlim = c(F_stat, 5)) +
  annotate("text", x = 3.29, y = .2, label = "F-statistic", size=10) +
  annotate("text", x = 3.18, y = .01, label = "p-value", size=10)
```

:::
:::

## Poll Everywhere Question 3


# Learning Objectives

1. Revisit data visualization for a numeric outcome and categorical variable (from Lesson 8).

2. Understand the different measures of variability within an Analysis of Variance (ANOVA) table.

3. Understand the F-statistic and F-distribution that is used to measure the ratio of between group and within group variability. 

::: lob
4.  Determine if groups of means are different from one another using a hypothesis test and F-distribution.
:::

## Reference: Steps in a Hypothesis Test

1.  Check the [**assumptions**]{style="color:#3070BF"}

2.  Set the [**level of significance**]{style="color:#3070BF"} $\alpha$

3.  Specify the [**null**]{style="color:#3070BF"} ( $H_0$ ) and [**alternative**]{style="color:#3070BF"} ( $H_A$ ) [**hypotheses**]{style="color:#3070BF"}

    1.  In symbols
    2.  In words
    3.  ~~Alternative: one- or two-sided?~~

4.  Calculate the [**test statistic**]{style="color:#3070BF"}.

5.  Calculate the [**p-value**]{style="color:#3070BF"} based on the observed test statistic and its sampling distribution

6.  Write a [**conclusion**]{style="color:#3070BF"} to the hypothesis test

    1.  Do we reject or fail to reject $H_0$?
    2.  Write a conclusion in the context of the problem

## Step 1: Check assumptions

The sampling distribution is an __F-distribution__, if...

- Sample sizes in each group group are large (each $n \ge 30$) 
    * OR the data are relatively normally distributed in each group
- Variability is "similar" in all group groups:
    * Is the within group variability about the same for each group?
    * As a rough rule of thumb, this condition is _violated if the standard deviation of one group is more than double the standard deviation of another group_

## Step 1: Check assumptions

- Use R to check both assumptions in our example

```{r}
genotype_groups <- famuss %>% 
  group_by(actn3.r577x) %>% 
  summarise(count = n(), 
            SD = sd(ndrm.ch))
genotype_groups
```

- Counts in each group are greater than 30!

```{r}
max(genotype_groups$SD) / min(genotype_groups$SD)
```

- Variability in one group vs. another is no more than 1.2 times!

## Step 3: Specify Hypotheses

::::::::::: columns
:::::: column
::::: blue
::: blue-ttl
General hypotheses
:::

::: blue-cont
To test for a difference in means across _k_ groups:

\begin{align}
H_0 &: \mu_1 = \mu_2 = ... = \mu_k\\
\text{vs. } H_A&: \text{At least one pair } \mu_i \neq \mu_j \text{ for } i \neq j
\end{align}
:::
:::::
::::::

:::::: column
::::: pink
::: pink-ttl
Hypotheses test for example
:::

::: pink-cont
\begin{align}
H_0 &: \mu_{CC} = \mu_{CT} = \mu_{TT}\\
\text{vs. } H_A&: \text{At least one pair } \mu_i \neq \mu_j \text{ for } i \neq j
\end{align}
:::
:::::
::::::
:::::::::::

## Step 4-5: Find the test statistic and p-value

- Our test statistic is an F-statistic
    - F-statistic: measurement of the ratio of variability between groups to variability within groups

 

- Our F-statistic follows an F-distribution
    - Which is why we cannot use something like the Z-distribution nor T-distribution
    
 

- So we'll need to find the F-statistic and its corresponding p-value using an F-distribution
    

## Step 4-5: Find the test statistic and p-value

* There are several options to run an ANOVA model (aka calculate F-statistic and p-value)
* Two most common are `lm` and `aov`
    * `lm` = linear model; will be using frequently in BSTA 512

::: columns
::: column
```{r}
lm(ndrm.ch ~ actn3.r577x, 
    data = famuss) %>% anova()
```
:::

::: column
```{r}
aov(ndrm.ch ~ actn3.r577x, 
    data = famuss) %>% summary()
```
:::
:::

## Step 6: Conclusion

\begin{align}
H_0 &: \mu_{CC} = \mu_{CT} = \mu_{TT}\\
\text{vs. } H_A&: \text{At least one pair} \mu_i \neq \mu_j \text{ for } i \neq j
\end{align}


-   Recall the $p$-value = `r round(0.04022, 4)`
-   Use $\alpha$ = 0.05
-   Do we reject or fail to reject $H_0$?

__Conclusion statement__:

* There is sufficient evidence that at least one of the genotype groups has a change in arm strength statistically different from the other groups. ( $p$-value =`r round(0.04022, 4)`)

## Final note

::: columns
::: column
- Recall, visually the three looked pretty close

- This is the case that I would also do some work to report the means and standard deviations of each genotype's percent change in non-dominant arm strength. 
:::
::: column
```{r}
famuss %>% 
  group_by(actn3.r577x) %>% 
  summarise(count = n(),
            mean = mean(ndrm.ch),
            SD = sd(ndrm.ch))
```
:::
:::

__Revised conclusion statement__:

* For people with CC genotype then mean percent change in arm non-dominant arm strength was 48.9% (SD = 30%). For CT, mean percent change was 53.2% (SD = 33.2%). For TT, mean percent change was 58.1% (SD = 35.7%). There is sufficient evidence that at least one of the genotype groups has a change in arm strength statistically different from the other groups. ( $p$-value =`r round(0.04022, 4)`)

